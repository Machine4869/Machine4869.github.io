<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>Flume-入门 | 哑舍</title><meta name="description" content="Flume-入门"><meta name="keywords" content="大数据"><meta name="author" content="Machine"><meta name="copyright" content="Machine"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/cat2.ico"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Flume-入门"><meta name="twitter:description" content="Flume-入门"><meta name="twitter:image" content="https://machine4869.gitee.io/img/default_p1.jpeg"><meta property="og:type" content="article"><meta property="og:title" content="Flume-入门"><meta property="og:url" content="https://machine4869.gitee.io/2019/09/11/20190911160645622/"><meta property="og:site_name" content="哑舍"><meta property="og:description" content="Flume-入门"><meta property="og:image" content="https://machine4869.gitee.io/img/default_p1.jpeg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="canonical" href="https://machine4869.gitee.io/2019/09/11/20190911160645622/"><link rel="prev" title="Azkaban" href="https://machine4869.gitee.io/2019/09/12/20190912163521905/"><link rel="next" title="java设计模式-23种设计模式" href="https://machine4869.gitee.io/2019/09/06/20190906210551001/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://machine4869.gitee.io/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: {"bookmark":{"title":"Snackbar.bookmark.title","message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">哑舍</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 更多</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 豆瓣电影</span></a></li><li><a class="site-page" href="/photos/"><i class="fa-fw fa fa-picture-o"></i><span> 照片墙</span></a></li></ul></div></div></span><span class="pull_right" id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/head.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">134</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">27</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">45</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 更多</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 豆瓣电影</span></a></li><li><a class="site-page" href="/photos/"><i class="fa-fw fa fa-picture-o"></i><span> 照片墙</span></a></li></ul></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Flume概述"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">Flume概述</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#问题引入"><span class="toc_mobile_items-number">1.1.</span> <span class="toc_mobile_items-text">问题引入</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Flume定义"><span class="toc_mobile_items-number">1.2.</span> <span class="toc_mobile_items-text">Flume定义</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Flume基础架构"><span class="toc_mobile_items-number">1.3.</span> <span class="toc_mobile_items-text">Flume基础架构</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Flume快速入门"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">Flume快速入门</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Flume安装"><span class="toc_mobile_items-number">2.1.</span> <span class="toc_mobile_items-text">Flume安装</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#官方案例–监控端口数据"><span class="toc_mobile_items-number">2.2.</span> <span class="toc_mobile_items-text">官方案例–监控端口数据</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#案例–实时监控单个追加文件"><span class="toc_mobile_items-number">2.3.</span> <span class="toc_mobile_items-text">案例–实时监控单个追加文件</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#案例–实时监控目录下多个新文件"><span class="toc_mobile_items-number">2.4.</span> <span class="toc_mobile_items-text">案例–实时监控目录下多个新文件</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#案例–实时监控目录下多个追加文件"><span class="toc_mobile_items-number">2.5.</span> <span class="toc_mobile_items-text">案例–实时监控目录下多个追加文件</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Flume进阶"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text">Flume进阶</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#案例：flume消费kafka数据到hdfs"><span class="toc_mobile_items-number">3.1.</span> <span class="toc_mobile_items-text">案例：flume消费kafka数据到hdfs</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#kafka-flume-logger测试"><span class="toc_mobile_items-number">3.1.1.</span> <span class="toc_mobile_items-text">kafka - flume - logger测试</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#kafka-flume-hdfs测试"><span class="toc_mobile_items-number">3.1.2.</span> <span class="toc_mobile_items-text">kafka - flume - hdfs测试</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#解析：hdfs配置中roll-和-round-的解释"><span class="toc_mobile_items-number">3.1.3.</span> <span class="toc_mobile_items-text">解析：hdfs配置中roll 和 round 的解释</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#解析：按不同topic在hdfs上分目录方案的原理"><span class="toc_mobile_items-number">3.1.4.</span> <span class="toc_mobile_items-text">解析：按不同topic在hdfs上分目录方案的原理</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#测试环境和生产环境下的配置"><span class="toc_mobile_items-number">3.1.5.</span> <span class="toc_mobile_items-text">测试环境和生产环境下的配置</span></a></li></ol></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#可能遇到的BUG"><span class="toc_mobile_items-number">4.</span> <span class="toc_mobile_items-text">可能遇到的BUG</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#nc客户端无法使用"><span class="toc_mobile_items-number">4.1.</span> <span class="toc_mobile_items-text">nc客户端无法使用</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#TODO"><span class="toc_mobile_items-number">5.</span> <span class="toc_mobile_items-text">TODO</span></a></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Flume概述"><span class="toc-number">1.</span> <span class="toc-text">Flume概述</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#问题引入"><span class="toc-number">1.1.</span> <span class="toc-text">问题引入</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Flume定义"><span class="toc-number">1.2.</span> <span class="toc-text">Flume定义</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Flume基础架构"><span class="toc-number">1.3.</span> <span class="toc-text">Flume基础架构</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Flume快速入门"><span class="toc-number">2.</span> <span class="toc-text">Flume快速入门</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Flume安装"><span class="toc-number">2.1.</span> <span class="toc-text">Flume安装</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#官方案例–监控端口数据"><span class="toc-number">2.2.</span> <span class="toc-text">官方案例–监控端口数据</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#案例–实时监控单个追加文件"><span class="toc-number">2.3.</span> <span class="toc-text">案例–实时监控单个追加文件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#案例–实时监控目录下多个新文件"><span class="toc-number">2.4.</span> <span class="toc-text">案例–实时监控目录下多个新文件</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#案例–实时监控目录下多个追加文件"><span class="toc-number">2.5.</span> <span class="toc-text">案例–实时监控目录下多个追加文件</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#Flume进阶"><span class="toc-number">3.</span> <span class="toc-text">Flume进阶</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#案例：flume消费kafka数据到hdfs"><span class="toc-number">3.1.</span> <span class="toc-text">案例：flume消费kafka数据到hdfs</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#kafka-flume-logger测试"><span class="toc-number">3.1.1.</span> <span class="toc-text">kafka - flume - logger测试</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#kafka-flume-hdfs测试"><span class="toc-number">3.1.2.</span> <span class="toc-text">kafka - flume - hdfs测试</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#解析：hdfs配置中roll-和-round-的解释"><span class="toc-number">3.1.3.</span> <span class="toc-text">解析：hdfs配置中roll 和 round 的解释</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#解析：按不同topic在hdfs上分目录方案的原理"><span class="toc-number">3.1.4.</span> <span class="toc-text">解析：按不同topic在hdfs上分目录方案的原理</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#测试环境和生产环境下的配置"><span class="toc-number">3.1.5.</span> <span class="toc-text">测试环境和生产环境下的配置</span></a></li></ol></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#可能遇到的BUG"><span class="toc-number">4.</span> <span class="toc-text">可能遇到的BUG</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#nc客户端无法使用"><span class="toc-number">4.1.</span> <span class="toc-text">nc客户端无法使用</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#TODO"><span class="toc-number">5.</span> <span class="toc-text">TODO</span></a></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(/img/default_p1.jpeg)"><div id="post-info"><div id="post-title"><div class="posttitle">Flume-入门</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 发表于 2019-09-11<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> 更新于 2019-11-28</time><span class="post-meta__separator">|</span><span><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E5%BC%8F/">大数据分布式</a><i class="fa fa-angle-right fa-fw" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E5%BC%8F/%E6%95%B0%E6%8D%AE%E9%87%87%E9%9B%86/">数据采集</a></span><div class="post-meta-wordcount"><i class="fa fa-file-word-o post-meta__icon fa-fw" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">4.3k</span><span class="post-meta__separator">|</span><i class="fa fa-clock-o post-meta__icon fa-fw" aria-hidden="true"></i><span>阅读时长: 18 分钟</span><div class="post-meta-pv-cv"><span class="post-meta__separator">|</span><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>阅读量:</span><span id="busuanzi_value_page_pv"></span><span class="post-meta__separator">|</span><i class="fa fa-comments-o post-meta__icon fa-fw" aria-hidden="true"></i><span>评论数:</span><a href="/2019/09/11/20190911160645622/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count comment-count" data-xid="/2019/09/11/20190911160645622/" itemprop="commentCount"></span></a></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><p>[TOC]</p>
<blockquote>
<p>参考：</p>
<ul>
<li><a href="http://www.atguigu.com/jsfx/3415.html" target="_blank" rel="noopener">http://www.atguigu.com/jsfx/3415.html</a></li>
<li><a href="https://www.bilibili.com/video/av65541678/?p=3" target="_blank" rel="noopener">https://www.bilibili.com/video/av65541678/?p=3</a></li>
</ul>
</blockquote>
<h1 id="Flume概述"><a href="#Flume概述" class="headerlink" title="Flume概述"></a>Flume概述</h1><h2 id="问题引入"><a href="#问题引入" class="headerlink" title="问题引入"></a>问题引入</h2><p>数据如何从java后台服务器(业务系统如springboot) 到 大数据集群(Hadooop生态圈)？</p>
<p>一般这两套不会使用一台服务器</p>
<p>后台跟页面交互，必须要保证实时性，反应要快。而大数据集群，跟多时候可以离线处理数据，实时要求不高。</p>
<p>数据来源：</p>
<p>业务数据：订单、支付 ===》Mysql</p>
<p>访问日志：访问、点击、搜索===&gt;磁盘文本，日志</p>
<p>这个数据采集的工具：Flume。</p>
<p>日志采集系统方案：Flume+Kafka+HDFS</p>
<p><a href="https://blog.csdn.net/weixin_38750084/article/details/82861555" target="_blank" rel="noopener">https://blog.csdn.net/weixin_38750084/article/details/82861555</a></p>
<p><a href="https://www.cnblogs.com/zyfd/p/9578252.html" target="_blank" rel="noopener">https://www.cnblogs.com/zyfd/p/9578252.html</a></p>
<h2 id="Flume定义"><a href="#Flume定义" class="headerlink" title="Flume定义"></a>Flume定义</h2><p>文档：<a href="http://flume.apache.org/" target="_blank" rel="noopener">http://flume.apache.org/</a></p>
<p>Java后台日志每时每刻产生数据，怎么存到HDFS里去？</p>
<ul>
<li>一：实时存到HDFS？每产生一个用户行为就写一个HDFS put？ ===》不可能，效率太低。</li>
<li>二：每天产生的日志写成一个XXX.log文件，然后调用定时任务每天凌晨写一次HDFS put？<ul>
<li>数据量大？不是问题，HDFS本来就擅长处理大数据。</li>
<li>实时性？一天的数据，只能当天凌晨做导入，还需要分析计算。造成的效果是，我当天浏览了商品，到了第二天才去给我相关推送。而我们现在的效果是，刚浏览了商品，立马就能得到推荐。怎么做？需要一个中间软件实时上传数据到HDFS===》Flume</li>
</ul>
</li>
</ul>
<p><strong>定义</strong></p>
<p>Flume是Cloudera提供的一个高可用的，高可靠的，分布式的海量日志采集、聚合和传输的系统。Flume基于流式架构，灵活简单。</p>
<p><a href="/2019/09/11/20190911160645622/%E5%9B%BE%E7%89%871.png" data-fancybox="group" data-caption="图片1" class="fancybox"><img alt="图片1" title="图片1" data-src="/2019/09/11/20190911160645622/%E5%9B%BE%E7%89%871.png" class="lazyload"></a></p>
<p>kafka: 流式的，对应实时系统</p>
<p>flume：对应离线系统</p>
<h2 id="Flume基础架构"><a href="#Flume基础架构" class="headerlink" title="Flume基础架构"></a>Flume基础架构</h2><p><a href="/2019/09/11/20190911160645622/%E5%9B%BE%E7%89%872.png" data-fancybox="group" data-caption="图片2" class="fancybox"><img alt="图片2" title="图片2" data-src="/2019/09/11/20190911160645622/%E5%9B%BE%E7%89%872.png" class="lazyload"></a></p>
<p><strong>Agent</strong></p>
<p>Agent是一个JVM进程，它以事件的形式将数据从源头送至目的，是Flume数据传输的基本单元。</p>
<p>Agent主要有3个部分组成，Source、Channel、Sink。</p>
<p><strong>Source</strong></p>
<p>Source是负责接收数据到Flume Agent的组件。Source组件可以处理各种类型、各种格式的日志数据，包括avro、thrift、exec、jms、spooling directory、netcat、sequence generator、syslog、http、legacy。</p>
<p><strong>Channel</strong></p>
<p>Channel是位于Source和Sink之间的缓冲区。因此，Channel允许Source和Sink运作在不同的速率上。Channel是线程安全的，可以同时处理几个Source的写入操作和几个Sink的读取操作。</p>
<p>Flume自带两种Channel：Memory Channel和File Channel。</p>
<p>Memory Channel是内存中的队列。Memory Channel在不需要关心数据丢失的情景下适用。如果需要关心数据丢失，那么Memory Channel就不应该使用，因为程序死亡、机器宕机或者重启都会导致数据丢失。</p>
<p>File Channel将所有事件写到磁盘。因此在程序关闭或机器宕机的情况下不会丢失数据。</p>
<p> <strong>Sink</strong></p>
<p>Sink不断地轮询Channel中的事件且批量地移除它们，并将这些事件批量写入到存储或索引系统、或者被发送到另一个Flume Agent。</p>
<p>Sink是完全事务性的。在从Channel批量删除数据之前，每个Sink用Channel启动一个事务。批量事件一旦成功写出到存储系统或下一个Flume Agent，Sink就利用Channel提交事务。事务一旦被提交，该Channel从自己的内部缓冲区删除事件。</p>
<p>Sink组件目的地包括hdfs、logger、avro、thrift、ipc、file、null、HBase、solr、自定义。</p>
<p><strong>Event</strong></p>
<p>传输单元，Flume数据传输的基本单元，以事件的形式将数据从源头送至目的地。</p>
<h1 id="Flume快速入门"><a href="#Flume快速入门" class="headerlink" title="Flume快速入门"></a>Flume快速入门</h1><h2 id="Flume安装"><a href="#Flume安装" class="headerlink" title="Flume安装"></a>Flume安装</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">http://archive.cloudera.com/cdh5/cdh/5/flume-ng-1.6.0-cdh5.16.1.tar.gz</span><br><span class="line"></span><br><span class="line">Flume运行在JVM之上</span><br><span class="line"></span><br><span class="line">进入conf</span><br><span class="line">vi flume-env.sh</span><br><span class="line">修改JAVA_HOME就行</span><br></pre></td></tr></table></figure></div>



<h2 id="官方案例–监控端口数据"><a href="#官方案例–监控端口数据" class="headerlink" title="官方案例–监控端口数据"></a>官方案例–监控端口数据</h2><p>案例需求：首先，Flume监控本机44444端口，然后通过telnet工具向本机44444端口发送消息，最后Flume将监听的数据实时显示在控制台。</p>
<p>分析：</p>
<p>NetCatSource    LoggerSink</p>
<p>![屏幕快照 2019-09-12 上午10.58.06](20190911160645622/屏幕快照 2019-09-12 上午10.58.06.png)</p>
<p>配置</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line">sudo yum install -y nc</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 进入flume home</span></span><br><span class="line">mkdir job</span><br><span class="line">cd job/</span><br><span class="line">touch netcat-flume-logger.conf</span><br><span class="line"></span><br><span class="line">文件来自：</span><br><span class="line">http://archive.cloudera.com/cdh5/cdh/5/flume-ng-1.6.0-cdh5.16.1/FlumeUserGuide.html</span><br><span class="line">1000个事件，一次事务传输100个事件</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> example.conf: A single-node Flume configuration</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = netcat</span><br><span class="line">a1.sources.r1.bind = localhost</span><br><span class="line">a1.sources.r1.port = 44444</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Describe the sink</span></span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Use a channel <span class="built_in">which</span> buffers events <span class="keyword">in</span> memory</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure></div>

<p>启动</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">$</span><span class="bash"> bin/flume-ng agent --conf conf/ --conf-file job/netcat-flume-logger.conf --name a1 -Dflume.root.logger=INFO,console</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 此时本机作为nc服务端启动了，它监听的是localhost:44444端口</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在mac上开一个客户端去连</span></span><br><span class="line">nc -u 10.211.55.14 44444</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 服务端会显示：</span></span><br><span class="line">Event: &#123; headers:&#123;&#125; body: 68 65 6C 6C 6F                                  hello &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">$</span><span class="bash"> bin/flume-ng agent -c conf/ -f job/netcat-flume-logger.conf -n a1 -Dflume.root.logger=INFO,console</span></span><br></pre></td></tr></table></figure></div>



<h2 id="案例–实时监控单个追加文件"><a href="#案例–实时监控单个追加文件" class="headerlink" title="案例–实时监控单个追加文件"></a>案例–实时监控单个追加文件</h2><p>案例需求：实时监控Hive日志，并上传到HDFS中</p>
<p>![屏幕快照 2019-09-12 下午1.36.43](20190911160645622/屏幕快照 2019-09-12 下午1.36.43.png)</p>
<p>先做输出到logger的案例</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line">exec 监控本地文件</span><br><span class="line">tail -f 可以监控文件变化</span><br><span class="line"></span><br><span class="line">Hive 设置日志存储目录: https://blog.csdn.net/qq_35495339/article/details/95105779</span><br><span class="line"></span><br><span class="line">touch file-flume-logger.conf</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = exec</span><br><span class="line">a1.sources.r1.command = tail -f /home/machine/apps/hive-1.1.0-cdh5.16.1/logs/hive.log</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Describe the sink</span></span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Use a channel <span class="built_in">which</span> buffers events <span class="keyword">in</span> memory</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">bin/flume-ng agent -c conf/ -f job/file-flume-logger.conf -n a1 -Dflume.root.logger=INFO,console</span><br><span class="line"><span class="meta">#</span><span class="bash"> 这时默认会先打印10条数据：Event</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动hive，写show databases; 触发hive.log日志改变，这时，flume logger控制台会实时打印变化的日志。</span></span><br></pre></td></tr></table></figure></div>



<p>现在做输出到HDFS的案例：HDFS sink</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line">Flume要想将数据输出到HDFS，必须持有Hadoop相关jar包</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 生产环境下以下配置很重要</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 滚动文件</span></span><br><span class="line">hdfs.rollInterval</span><br><span class="line">hdfs.rollSize</span><br><span class="line">hdfs.rollCount</span><br><span class="line"></span><br><span class="line">hdfs.batchSize</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 滚动文件夹（Hive也按天分区）</span></span><br><span class="line">hdfs.round</span><br><span class="line">hdfs.roundValue</span><br><span class="line">hdfs.roundUnit</span><br><span class="line"></span><br><span class="line">hdfs.useLocalTimeStamp = true</span><br><span class="line"></span><br><span class="line">以下是生产环境常用：</span><br><span class="line">file-flume-hdfs.conf</span><br><span class="line"><span class="meta">#</span><span class="bash"> =============================</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = exec</span><br><span class="line">a1.sources.r1.command = tail -F /home/machine/apps/hive-1.1.0-cdh5.16.1/logs/hive.log</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Describe the sink</span></span><br><span class="line">a1.sinks.k1.type = hdfs</span><br><span class="line">a1.sinks.k1.hdfs.path = hdfs://localhost:9000/flume/%Y%m%d/%H</span><br><span class="line"><span class="meta">#</span><span class="bash">上传文件的前缀</span></span><br><span class="line">a1.sinks.k1.hdfs.filePrefix = logs-</span><br><span class="line"><span class="meta">#</span><span class="bash">是否按照时间滚动文件夹</span></span><br><span class="line">a1.sinks.k1.hdfs.round = true</span><br><span class="line"><span class="meta">#</span><span class="bash">多少时间单位创建一个新的文件夹</span></span><br><span class="line">a1.sinks.k1.hdfs.roundValue = 1</span><br><span class="line"><span class="meta">#</span><span class="bash">重新定义时间单位</span></span><br><span class="line">a1.sinks.k1.hdfs.roundUnit = hour</span><br><span class="line"><span class="meta">#</span><span class="bash">是否使用本地时间戳</span></span><br><span class="line">a1.sinks.k1.hdfs.useLocalTimeStamp = true</span><br><span class="line"><span class="meta">#</span><span class="bash">积攒多少个Event才flush到HDFS一次</span></span><br><span class="line">a1.sinks.k1.hdfs.batchSize = 1000</span><br><span class="line"><span class="meta">#</span><span class="bash">设置文件类型，可支持压缩</span></span><br><span class="line">a1.sinks.k1.hdfs.fileType = DataStream</span><br><span class="line"><span class="meta">#</span><span class="bash">多久生成一个新的文件，生产环境不要设置30s，太快了</span></span><br><span class="line">a1.sinks.k1.hdfs.rollInterval = 30</span><br><span class="line"><span class="meta">#</span><span class="bash">设置每个文件的滚动大小，不超过128m，即hdfs块大小</span></span><br><span class="line">a1.sinks.k1.hdfs.rollSize = 134217700</span><br><span class="line"><span class="meta">#</span><span class="bash">文件的滚动与Event数量无关</span></span><br><span class="line">a1.sinks.k1.hdfs.rollCount = 0</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Use a channel <span class="built_in">which</span> buffers events <span class="keyword">in</span> memory</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">bin/flume-ng agent -c conf/ -f job/file-flume-hdfs.conf -n a1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 会自动在hdfs上创建flume文件夹</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 每30s会滚动一个文件，但前提是这30s内有新数据进来</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 去hive里做一个触发，过30s会滚动一个新文件，	logs-.1568271636815</span></span><br></pre></td></tr></table></figure></div>



<h2 id="案例–实时监控目录下多个新文件"><a href="#案例–实时监控目录下多个新文件" class="headerlink" title="案例–实时监控目录下多个新文件"></a>案例–实时监控目录下多个新文件</h2><p>tail -f 是一行一行读的，现在有个目录，不停的放新文件，且文件放好后，不再修改。</p>
<p>spooldir source</p>
<p>只要目录有新文件就上传，不是说文件有新内容</p>
<p>![屏幕快照 2019-09-12 下午3.12.03](20190911160645622/屏幕快照 2019-09-12 下午3.12.03.png)</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line">touch dir-flume-hdfs.conf</span><br><span class="line">复制file-flume-hdfs.conf</span><br><span class="line"></span><br><span class="line">fileSuffix: 默认.COMPLETED 。 通过文件后缀过滤掉已添加的文件</span><br><span class="line"><span class="meta">#</span><span class="bash"> 要上传/不上传 的文件</span></span><br><span class="line">includePattern</span><br><span class="line">ignorePattern</span><br><span class="line">修改以下内容：</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Describe/configure the <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = spooldir</span><br><span class="line">a1.sources.r1.spoolDir = /home/machine/apps/flume-1.6.0-cdh5.16.1/upload</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 准备txt文件</span></span><br><span class="line">bin/flume-ng agent -c conf/ -f job/dir-flume-hdfs.conf -n a1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 向upload写一个文件</span></span><br><span class="line">cp 1.txt upload/</span><br><span class="line">ll upload/</span><br><span class="line">1.txt.COMPLETED</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 不可能监控动态变化的数据，不要创建文件后再修改文件，不要取同名文件，不要取名后缀为.COMPLETED的文件</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 被监控文件夹每500ms扫描一次文件变动</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash">忽略所有以.tmp结尾的文件，不上传</span></span><br><span class="line">a3.sources.r3.ignorePattern = ([^ ]*\.tmp)</span><br><span class="line"><span class="meta">#</span><span class="bash"> 适合场景：.tmp表示数据正在实时追加，追加完后才去掉tmp后缀，这时，上传改文件，并加上.COMPLETED后缀</span></span><br></pre></td></tr></table></figure></div>

<p>产生日志策略：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">在生产一个文件的数据时（追加数据是一个过程），以XXX.tmp命令，这样可以让spooldir忽略监控。</span><br><span class="line">当文件生产完毕，不再修改时，修改其命名，去掉tmp后缀，这时spooldir会立马监控到该文件并且上传，然后加上.COMPLETED</span><br></pre></td></tr></table></figure></div>



<h2 id="案例–实时监控目录下多个追加文件"><a href="#案例–实时监控目录下多个追加文件" class="headerlink" title="案例–实时监控目录下多个追加文件"></a>案例–实时监控目录下多个追加文件</h2><p>目录下的多个新文件，都能被监控</p>
<p>souce对比：</p>
<p>exec: 监控实时追加的文件，不保证数据不丢失。</p>
<p>spooldir：监控目录下产生的新文件，但不监控文件内容变化，延迟高，不实时。</p>
<p>taildir : 支持断点续传，数据不丢失，且实时监控<strong>多个文件夹的多个文件</strong>。</p>
<p>需求：监控一个文件夹的 新文件和旧文件追加，并上传至HDFS</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">被监控目录：flume&#x2F;files</span><br></pre></td></tr></table></figure></div>



<p>先做taildir — logger</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">cd job</span><br><span class="line">touch files-flume-logger.conf</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建files目录</span></span><br><span class="line">mkdir files</span><br><span class="line">cd files/</span><br><span class="line">touch file1.txt</span><br><span class="line">touch file2.txt</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 写files-flume-logger.conf</span></span><br></pre></td></tr></table></figure></div>

<p>files-flume-logger.conf</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> example.conf: A single-node Flume configuration</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Name the components on this agent</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Describe/configure the <span class="built_in">source</span></span></span><br><span class="line"><span class="meta">#</span><span class="bash"> positionFile: 断点续传的记录文件</span></span><br><span class="line">a1.sources.r1.type = TAILDIR</span><br><span class="line">a1.sources.r1.filegroups = f1 f2</span><br><span class="line">a1.sources.r1.filegroups.f1 = /home/machine/apps/flume-1.6.0-cdh5.16.1/files/file1.txt</span><br><span class="line">a1.sources.r1.filegroups.f2 = /home/machine/apps/flume-1.6.0-cdh5.16.1/files/file2.txt</span><br><span class="line">a1.sources.r1.positionFile = /home/machine/apps/flume-1.6.0-cdh5.16.1/position/position.json</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Describe the sink</span></span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Use a channel <span class="built_in">which</span> buffers events <span class="keyword">in</span> memory</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> Bind the <span class="built_in">source</span> and sink to the channel</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure></div>

<p>运行</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent --conf conf/ --conf-file job/files-flume-logger.conf --name a1 -Dflume.root.logger=INFO,console</span><br><span class="line"></span><br><span class="line">echo hello &gt;&gt; file1.txt</span><br><span class="line">echo flume &gt;&gt; file2.txt</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在控制台看到了变化</span></span><br></pre></td></tr></table></figure></div>

<p>测试断点续传</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">把flume监控手动挂掉。然后生产数据</span><br><span class="line"></span><br><span class="line">echo hahah &gt;&gt; file2.txt</span><br><span class="line"></span><br><span class="line">重启后，可以断点续传</span><br></pre></td></tr></table></figure></div>

<p>测试是否可以在一个组直接放2个文件</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">a1.sources.r1.filegroups = f1</span><br><span class="line">a1.sources.r1.filegroups.f1 = /home/machine/apps/flume-1.6.0-cdh5.16.1/files/file1.txt</span><br><span class="line">a1.sources.r1.filegroups.f1 = /home/machine/apps/flume-1.6.0-cdh5.16.1/files/file2.txt</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 结论是这种写法不行，一个组只能配一个文件，否则会被后者覆盖</span></span><br></pre></td></tr></table></figure></div>



<h1 id="Flume进阶"><a href="#Flume进阶" class="headerlink" title="Flume进阶"></a>Flume进阶</h1><h2 id="案例：flume消费kafka数据到hdfs"><a href="#案例：flume消费kafka数据到hdfs" class="headerlink" title="案例：flume消费kafka数据到hdfs"></a>案例：flume消费kafka数据到hdfs</h2><p>需求</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">kafka &gt;  kafka source  &gt;  flume channal  &gt;  hdfs sink  &gt;  hdfs</span><br><span class="line"></span><br><span class="line">Source组件实时去消费Kafka业务Topic获取数据，将消费后的数据通过Flume Sink组件发送到HDFS进行存储。</span><br></pre></td></tr></table></figure></div>

<p>环境</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Kafka、Flume、Hadoop（HDFS可用）</span><br></pre></td></tr></table></figure></div>

<p>启动kafka简单生产者</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 启动zk</span></span><br><span class="line"><span class="meta">$</span><span class="bash">ZOOKEEPER_HOME/bin/zkServer.sh start</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动kafka</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动阻塞进程</span></span><br><span class="line">bin/kafka-server-start.sh config/server.properties</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动守护进行</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> bin/kafka-server-start.sh -daemon config/server.propertie</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 创建2个topic</span></span><br><span class="line">./kafka-topics.sh --create --zookeeper mxxcentos7:2181 --replication-factor 1 --partitions 3 --topic my-kafka-topic</span><br><span class="line">./kafka-topics.sh --create --zookeeper mxxcentos7:2181 --replication-factor 1 --partitions 3 --topic my-kafka-topic2</span><br><span class="line"><span class="meta">#</span><span class="bash"> 查看Topic：</span></span><br><span class="line">./kafka-topics.sh --list --zookeeper mxxcentos7:2181</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动生产者：</span></span><br><span class="line">./kafka-console-producer.sh --broker-list mxxcentos7:9092 --topic my-kafka-topic</span><br><span class="line">./kafka-console-producer.sh --broker-list mxxcentos7:9092 --topic my-kafka-topic2</span><br><span class="line"><span class="meta">#</span><span class="bash"> 启动消费者：./kafka-console-consumer.sh --bootstrap-server mxxcentos7:9092 --topic my-kafka-topic --from-beginning</span></span><br></pre></td></tr></table></figure></div>



<h3 id="kafka-flume-logger测试"><a href="#kafka-flume-logger测试" class="headerlink" title="kafka - flume - logger测试"></a>kafka - flume - logger测试</h3><p>先做一个sink为logger的测试一下</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">cd apps/flume-1.6.0-cdh5.16.1/job/</span><br><span class="line">touch kafka-flume-logger.conf</span><br></pre></td></tr></table></figure></div>

<p>kafka-flume-logger.conf</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 给agent组件命名</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置 kafka <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = org.apache.flume.source.kafka.KafkaSource</span><br><span class="line"><span class="meta">#</span><span class="bash"> List of brokers <span class="keyword">in</span> the Kafka cluster used by the <span class="built_in">source</span> （以逗号分隔）</span></span><br><span class="line">a1.sources.r1.kafka.bootstrap.servers = mxxcentos7:9092</span><br><span class="line"><span class="meta">#</span><span class="bash"> Comma-separated（以逗号分隔） list of topics the kafka consumer will <span class="built_in">read</span> messages from.</span></span><br><span class="line">a1.sources.r1.kafka.topics = my-kafka-topic,my-kafka-topic2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 其他可选项</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Maximum number of messages written to Channel <span class="keyword">in</span> one batch (default 1000)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> a1.sources.r1.batchSize = 5000</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Maximum time (<span class="keyword">in</span> ms) before a batch will be written to Channel The batch will be written whenever the first of size and time will be reached. (default 1000)</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> a1.sources.r1.batchDurationMillis = = 2000</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Regex that defines <span class="built_in">set</span> of topics the <span class="built_in">source</span> is subscribed on. This property has higher priority than kafka.topics and overrides kafka.topics <span class="keyword">if</span> exists.</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> a1.sources.r1.kafka.topics.regex</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> Unique identified of consumer group. Setting the same id <span class="keyword">in</span> multiple sources or agents indicates that they are part of the same consumer group</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> a1.sources.r1.kafka.consumer.group.id = custom.g.id</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置 sink</span></span><br><span class="line">a1.sinks.k1.type = logger</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置channels：mem类型，1000个事件，每次传10个</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 将sources和sinks绑定到channels</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure></div>

<p>启动</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">bin/flume-ng agent --conf conf/ --conf-file job/kafka-flume-logger.conf --name a1 -Dflume.root.logger=INFO,console</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 在kafka生产者里生产数据，看logger sink 的接受效果，如下</span></span><br><span class="line">2019-11-05 14:24:50,615 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;topic=my-kafka-topic, partition=0, timestamp=1572935089618&#125; body: 78 69 78 69 78 69                               xixixi &#125;</span><br></pre></td></tr></table></figure></div>



<h3 id="kafka-flume-hdfs测试"><a href="#kafka-flume-hdfs测试" class="headerlink" title="kafka - flume - hdfs测试"></a>kafka - flume - hdfs测试</h3><p>将上面案例的sink改成hdfs sink</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 开启hdfs</span></span><br><span class="line">start-dfs.sh</span><br><span class="line"><span class="meta">#</span><span class="bash"> mxxcentos7:50070</span></span><br><span class="line"></span><br><span class="line">cd job/</span><br><span class="line">touch kafka-flume-hdfs.conf</span><br></pre></td></tr></table></figure></div>

<p>kafka-flume-hdfs.conf</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 给agent组件命名</span></span><br><span class="line">a1.sources = r1</span><br><span class="line">a1.sinks = k1</span><br><span class="line">a1.channels = c1</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置 kafka <span class="built_in">source</span></span></span><br><span class="line">a1.sources.r1.type = org.apache.flume.source.kafka.KafkaSource</span><br><span class="line"><span class="meta">#</span><span class="bash"> List of brokers <span class="keyword">in</span> the Kafka cluster used by the <span class="built_in">source</span> （以逗号分隔）</span></span><br><span class="line">a1.sources.r1.kafka.bootstrap.servers = mxxcentos7:9092</span><br><span class="line"><span class="meta">#</span><span class="bash"> Comma-separated（以逗号分隔） list of topics the kafka consumer will <span class="built_in">read</span> messages from.</span></span><br><span class="line">a1.sources.r1.kafka.topics = my-kafka-topic,my-kafka-topic2</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> --------修改的部分 start-------------------</span></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置 sink</span></span><br><span class="line">a1.sinks.k1.type = hdfs</span><br><span class="line"><span class="meta">#</span><span class="bash"> 按小时分目录（也可以按天）</span></span><br><span class="line">a1.sinks.k1.hdfs.path = hdfs://mxxcentos7:9000/report-form-data/flume/%&#123;topic&#125;/%Y%m%d/%H</span><br><span class="line"><span class="meta">#</span><span class="bash"> 上传文件的前缀</span></span><br><span class="line">a1.sinks.k1.hdfs.filePrefix = logs-</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置滚动文件夹规则</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 是否按照时间滚动文件夹（没达到hdfs.batchSize但是达到了指定时间，也要产生滚动）</span></span><br><span class="line">a1.sinks.k1.hdfs.round = true</span><br><span class="line"><span class="meta">#</span><span class="bash"> 重新定义时间单位</span></span><br><span class="line">a1.sinks.k1.hdfs.roundUnit = hour</span><br><span class="line"><span class="meta">#</span><span class="bash"> 多少时间单位创建一个新的文件夹（与hdfs.roundUnit，hdfs.path配合）</span></span><br><span class="line">a1.sinks.k1.hdfs.roundValue = 1</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 是否使用本地时间戳</span></span><br><span class="line">a1.sinks.k1.hdfs.useLocalTimeStamp = true</span><br><span class="line"><span class="meta">#</span><span class="bash"> 积攒多少个Event才flush到HDFS一次</span></span><br><span class="line">a1.sinks.k1.hdfs.batchSize = 1000</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置文件类型，可支持压缩</span></span><br><span class="line">a1.sinks.k1.hdfs.fileType = DataStream</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置滚动文件规则</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 多久生成一个新的文件，生产环境不要设置30s，太快了</span></span><br><span class="line">a1.sinks.k1.hdfs.rollInterval = 30</span><br><span class="line"><span class="meta">#</span><span class="bash"> 设置每个文件的滚动大小，不超过128m，即hdfs块大小</span></span><br><span class="line">a1.sinks.k1.hdfs.rollSize = 134217700</span><br><span class="line"><span class="meta">#</span><span class="bash"> 文件的滚动与Event数量无关</span></span><br><span class="line">a1.sinks.k1.hdfs.rollCount = 0</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> --------修改的部分 end -------------------</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 配置channels：mem类型，1000个事件，每次传10个</span></span><br><span class="line">a1.channels.c1.type = memory</span><br><span class="line">a1.channels.c1.capacity = 1000</span><br><span class="line">a1.channels.c1.transactionCapacity = 100</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 将sources和sinks绑定到channels</span></span><br><span class="line">a1.sources.r1.channels = c1</span><br><span class="line">a1.sinks.k1.channel = c1</span><br></pre></td></tr></table></figure></div>



<p>启动</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> Flume要想将数据输出到HDFS，必须持有Hadoop相关jar包(chd版本的已经集成过了，不用管)</span></span><br><span class="line"></span><br><span class="line">bin/flume-ng agent -c conf/ -f job/kafka-flume-hdfs.conf -n a1</span><br><span class="line"><span class="meta">#</span><span class="bash"> 会自动在hdfs上创建文件夹</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 每30s会滚动一个文件，但前提是这30s内有新数据进来</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 去kafka生产者生产点数据，测试一下30s文件滚动的效果</span></span><br></pre></td></tr></table></figure></div>

<p>hdfs上的数据效果：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 文件目录(自动生成)</span></span><br><span class="line">/report-form-data/flume/my-kafka-topic/20191105/16</span><br><span class="line">/report-form-data/flume/my-kafka-topic2/20191105/16</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 目录下的文件</span></span><br><span class="line">logs-.1572937573119</span><br><span class="line">logs-.1572937799038</span><br><span class="line">logs-.1572937910088</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 数据样式</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> logs-.1572937799038</span></span><br><span class="line">444ddd</span><br><span class="line">aaa111</span><br><span class="line">bbb222</span><br><span class="line">ccc333</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> logs-.1572937910088</span></span><br><span class="line">ddd444</span><br></pre></td></tr></table></figure></div>



<h3 id="解析：hdfs配置中roll-和-round-的解释"><a href="#解析：hdfs配置中roll-和-round-的解释" class="headerlink" title="解析：hdfs配置中roll 和 round 的解释"></a>解析：hdfs配置中roll 和 round 的解释</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 生产环境下以下配置很重要</span></span><br><span class="line"><span class="meta">#</span><span class="bash"> 滚动文件</span></span><br><span class="line">hdfs.rollInterval</span><br><span class="line">hdfs.rollSize</span><br><span class="line">hdfs.rollCount</span><br><span class="line"></span><br><span class="line">hdfs.batchSize</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 滚动文件夹（Hive也按天分区）</span></span><br><span class="line">hdfs.round</span><br><span class="line">hdfs.roundValue</span><br><span class="line">hdfs.roundUnit</span><br></pre></td></tr></table></figure></div>



<h3 id="解析：按不同topic在hdfs上分目录方案的原理"><a href="#解析：按不同topic在hdfs上分目录方案的原理" class="headerlink" title="解析：按不同topic在hdfs上分目录方案的原理"></a>解析：按不同topic在hdfs上分目录方案的原理</h3><p>1、kafka.topics可以配置多个topic，然后hdfs.path的目录设置为<code>/report-form-data/flume/%{topic}/%Y%m%d/%H</code>。</p>
<p>实现思路：kafka发的数据，每个event的headers中有topic字段，其中<code>%{topic}</code>就是取这个字段当目录</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 在kafka生产者里生产数据，看logger sink 的接受效果，如下</span></span><br><span class="line">2019-11-05 14:24:50,615 (SinkRunner-PollingRunner-DefaultSinkProcessor) [INFO - org.apache.flume.sink.LoggerSink.process(LoggerSink.java:95)] Event: &#123; headers:&#123;topic=my-kafka-topic, partition=0, timestamp=1572935089618&#125; body: 78 69 78 69 78 69                               xixixi &#125;</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> 如果有更深层的要求需要自己编写flume拦截器代码解析这个字段</span></span><br></pre></td></tr></table></figure></div>



<h3 id="测试环境和生产环境下的配置"><a href="#测试环境和生产环境下的配置" class="headerlink" title="测试环境和生产环境下的配置"></a>测试环境和生产环境下的配置</h3><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#</span><span class="bash"> 多久生成一个新的文件，生产环境不要设置30s，太快了</span></span><br><span class="line">a1.sinks.k1.hdfs.rollInterval = 30</span><br></pre></td></tr></table></figure></div>





<h1 id="可能遇到的BUG"><a href="#可能遇到的BUG" class="headerlink" title="可能遇到的BUG"></a>可能遇到的BUG</h1><h2 id="nc客户端无法使用"><a href="#nc客户端无法使用" class="headerlink" title="nc客户端无法使用"></a>nc客户端无法使用</h2><div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">shell</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">报错：Ncat: Connection refused.</span><br><span class="line"></span><br><span class="line"><span class="meta">#</span><span class="bash"> centos7安装netcat:</span></span><br><span class="line">https://my.oschina.net/u/3530967/blog/1560985</span><br></pre></td></tr></table></figure></div>



<h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><p>继续以上内容</p>
<p>问题：能同时监控 旧文件追加 和 新文件产生吗 ？</p>
<p>以上都是基于mem channal的</p>
<p>一个对比：</p>
<p>sqoop: 传统关系型数据库（musql） –&gt; sqoop   –&gt; 大数据平台（Hadoop hdfs/hive/hbase）</p>
<p>可以写定时器实时增量导入。</p>
<p>定位是数据迁移。导入结构化数据。Sqoop是关系型数据库和HDFS之间的一个桥梁。</p>
<p>Flume：监控文件/文件夹/端口/socket  数据变化   –&gt;Flume –&gt;  大数据平台（Hadoop hdfs/hive/hbase）</p>
<p>定位主要是各种来源的日志采集。</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Machine</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://machine4869.gitee.io/2019/09/11/20190911160645622/">https://machine4869.gitee.io/2019/09/11/20190911160645622/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://machine4869.gitee.io">哑舍</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据    </a></div><div class="post_share"><div class="social-share" data-image="/img/default_p1.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/wechat.png" alt="微信"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/alipay.jpg" alt="支付宝"><div class="post-qr-code__desc">支付宝</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2019/09/12/20190912163521905/"><img class="prev_cover lazyload" data-src="/img/default_p7.jpeg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>Azkaban</span></div></a></div><div class="next-post pull_right"><a href="/2019/09/06/20190906210551001/"><img class="next_cover lazyload" data-src="/img/default_p5.jpeg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>java设计模式-23种设计模式</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2019/12/26/20191226144408846/" title="ELK-搜索引擎"><img class="relatedPosts_cover lazyload"data-src="/img/default_p1.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-12-26</div><div class="relatedPosts_title">ELK-搜索引擎</div></div></a></div><div class="relatedPosts_item"><a href="/2019/12/11/20191211154140441/" title="数据仓库-业务数据仓库"><img class="relatedPosts_cover lazyload"data-src="/img/default_p10.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-12-11</div><div class="relatedPosts_title">数据仓库-业务数据仓库</div></div></a></div><div class="relatedPosts_item"><a href="/2019/12/04/20191204140743901/" title="数据仓库-用户行为数据仓库"><img class="relatedPosts_cover lazyload"data-src="/img/default_p4.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-12-04</div><div class="relatedPosts_title">数据仓库-用户行为数据仓库</div></div></a></div><div class="relatedPosts_item"><a href="/2019/11/21/20191121155413741/" title="数据仓库-用户行为数据采集"><img class="relatedPosts_cover lazyload"data-src="/img/default_p1.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-11-21</div><div class="relatedPosts_title">数据仓库-用户行为数据采集</div></div></a></div><div class="relatedPosts_item"><a href="/2019/11/21/20191121140654751/" title="Ambari-Hadoop Web UI"><img class="relatedPosts_cover lazyload"data-src="/img/default_p7.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-11-21</div><div class="relatedPosts_title">Ambari-Hadoop Web UI</div></div></a></div><div class="relatedPosts_item"><a href="/2019/11/19/20191119151208934/" title="Kettle-ETL工具&数据抽取"><img class="relatedPosts_cover lazyload"data-src="/img/default_p5.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-11-19</div><div class="relatedPosts_title">Kettle-ETL工具&数据抽取</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div class="vcomment" id="vcomment"></div><script src="https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js"></script><script>var notify = true == true ? true : false;
var verify = false == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;

window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'yPVvDIaWlODDhs0bbECwLIIp-gzGzoHsz',
  appKey:'VyOIa40LxnjURzW1HUCiwTpV',
  placeholder:'记得留下你的昵称及邮箱，以便收到答复~',
  avatar:'monsterid',
  guest_info:guest_info,
  pageSize:'10',
  lang:'zh-cn',
  recordIP: true
});</script></div></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2020 By Machine</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://machine4869.gitee.io/">blog</a>!</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">简</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script id="canvas_nest" color="215,215,215" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/canvas-nest.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>