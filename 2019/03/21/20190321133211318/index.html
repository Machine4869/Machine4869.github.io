<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>python爬虫(3)-Scrapy框架 | 哑舍</title><meta name="description" content="python爬虫(3)-Scrapy框架"><meta name="keywords" content="python爬虫"><meta name="author" content="Machine"><meta name="copyright" content="Machine"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/cat2.ico"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="python爬虫(3)-Scrapy框架"><meta name="twitter:description" content="python爬虫(3)-Scrapy框架"><meta name="twitter:image" content="https://machine4869.gitee.io/img/default_p4.jpeg"><meta property="og:type" content="article"><meta property="og:title" content="python爬虫(3)-Scrapy框架"><meta property="og:url" content="https://machine4869.gitee.io/2019/03/21/20190321133211318/"><meta property="og:site_name" content="哑舍"><meta property="og:description" content="python爬虫(3)-Scrapy框架"><meta property="og:image" content="https://machine4869.gitee.io/img/default_p4.jpeg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="canonical" href="https://machine4869.gitee.io/2019/03/21/20190321133211318/"><link rel="prev" title="java设计模式-UML简述&amp;软件设计七大原则" href="https://machine4869.gitee.io/2019/03/26/20190326162203290/"><link rel="next" title="MongoDB(by python)" href="https://machine4869.gitee.io/2019/03/04/20190304105434006/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://machine4869.gitee.io/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: {"bookmark":{"title":"Snackbar.bookmark.title","message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">哑舍</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 更多</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 豆瓣电影</span></a></li><li><a class="site-page" href="/photos/"><i class="fa-fw fa fa-picture-o"></i><span> 照片墙</span></a></li></ul></div></div></span><span class="pull_right" id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/head.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">134</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">27</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">45</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 更多</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 豆瓣电影</span></a></li><li><a class="site-page" href="/photos/"><i class="fa-fw fa fa-picture-o"></i><span> 照片墙</span></a></li></ul></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#Spider"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">Spider</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#Scrapy-框架"><span class="toc_mobile_items-number">1.1.</span> <span class="toc_mobile_items-text">Scrapy 框架</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#数据抓取基础"><span class="toc_mobile_items-number">1.1.1.</span> <span class="toc_mobile_items-text">数据抓取基础</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#概述-amp-架构图-amp-运作流程-amp-安装"><span class="toc_mobile_items-number">1.1.1.1.</span> <span class="toc_mobile_items-text">概述&amp;架构图&amp;运作流程&amp;安装</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#入门案例"><span class="toc_mobile_items-number">1.1.1.2.</span> <span class="toc_mobile_items-text">入门案例</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#关于日志"><span class="toc_mobile_items-number">1.1.1.3.</span> <span class="toc_mobile_items-text">关于日志</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#实现翻页"><span class="toc_mobile_items-number">1.1.1.4.</span> <span class="toc_mobile_items-text">实现翻页</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#item"><span class="toc_mobile_items-number">1.1.1.5.</span> <span class="toc_mobile_items-text">item</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-3"><a class="toc_mobile_items-link" href="#scrapy深入"><span class="toc_mobile_items-number">1.1.2.</span> <span class="toc_mobile_items-text">scrapy深入</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#debug日志-amp-scrapy-shell-amp-settings-py-amp-pipline"><span class="toc_mobile_items-number">1.1.2.1.</span> <span class="toc_mobile_items-text">debug日志 &amp; scrapy shell &amp; settings.py &amp; pipline</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#综合案例-苏宁图书爬虫"><span class="toc_mobile_items-number">1.1.2.2.</span> <span class="toc_mobile_items-text">综合案例-苏宁图书爬虫</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-4"><a class="toc_mobile_items-link" href="#crawlspider"><span class="toc_mobile_items-number">1.1.2.3.</span> <span class="toc_mobile_items-text">crawlspider</span></a></li></ol></li></ol></li></ol></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#Spider"><span class="toc-number">1.</span> <span class="toc-text">Spider</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#Scrapy-框架"><span class="toc-number">1.1.</span> <span class="toc-text">Scrapy 框架</span></a><ol class="toc-child"><li class="toc-item toc-level-3"><a class="toc-link" href="#数据抓取基础"><span class="toc-number">1.1.1.</span> <span class="toc-text">数据抓取基础</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#概述-amp-架构图-amp-运作流程-amp-安装"><span class="toc-number">1.1.1.1.</span> <span class="toc-text">概述&amp;架构图&amp;运作流程&amp;安装</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#入门案例"><span class="toc-number">1.1.1.2.</span> <span class="toc-text">入门案例</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#关于日志"><span class="toc-number">1.1.1.3.</span> <span class="toc-text">关于日志</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#实现翻页"><span class="toc-number">1.1.1.4.</span> <span class="toc-text">实现翻页</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#item"><span class="toc-number">1.1.1.5.</span> <span class="toc-text">item</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#scrapy深入"><span class="toc-number">1.1.2.</span> <span class="toc-text">scrapy深入</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#debug日志-amp-scrapy-shell-amp-settings-py-amp-pipline"><span class="toc-number">1.1.2.1.</span> <span class="toc-text">debug日志 &amp; scrapy shell &amp; settings.py &amp; pipline</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#综合案例-苏宁图书爬虫"><span class="toc-number">1.1.2.2.</span> <span class="toc-text">综合案例-苏宁图书爬虫</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#crawlspider"><span class="toc-number">1.1.2.3.</span> <span class="toc-text">crawlspider</span></a></li></ol></li></ol></li></ol></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(/img/default_p4.jpeg)"><div id="post-info"><div id="post-title"><div class="posttitle">python爬虫(3)-Scrapy框架</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 发表于 2019-03-21<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> 更新于 2019-11-28</time><span class="post-meta__separator">|</span><span><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/python%E7%88%AC%E8%99%AB/">python爬虫</a></span><div class="post-meta-wordcount"><i class="fa fa-file-word-o post-meta__icon fa-fw" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">1.8k</span><span class="post-meta__separator">|</span><i class="fa fa-clock-o post-meta__icon fa-fw" aria-hidden="true"></i><span>阅读时长: 8 分钟</span><div class="post-meta-pv-cv"><span class="post-meta__separator">|</span><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>阅读量:</span><span id="busuanzi_value_page_pv"></span><span class="post-meta__separator">|</span><i class="fa fa-comments-o post-meta__icon fa-fw" aria-hidden="true"></i><span>评论数:</span><a href="/2019/03/21/20190321133211318/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count comment-count" data-xid="/2019/03/21/20190321133211318/" itemprop="commentCount"></span></a></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><blockquote>
<p>本文档由脑图导出，地址：<a href="http://naotu.baidu.com/file/3adea0eca05e3c3f081290142732313d?token=b14e7b97ee7411e0" target="_blank" rel="noopener">Spider脑图</a></p>
<p>参考：heima</p>
</blockquote>
<h1 id="Spider"><a href="#Spider" class="headerlink" title="Spider"></a>Spider</h1><h2 id="Scrapy-框架"><a href="#Scrapy-框架" class="headerlink" title="Scrapy 框架"></a>Scrapy 框架</h2><h3 id="数据抓取基础"><a href="#数据抓取基础" class="headerlink" title="数据抓取基础"></a>数据抓取基础</h3><h4 id="概述-amp-架构图-amp-运作流程-amp-安装"><a href="#概述-amp-架构图-amp-运作流程-amp-安装" class="headerlink" title="概述&amp;架构图&amp;运作流程&amp;安装"></a>概述&amp;架构图&amp;运作流程&amp;安装</h4><p>概述<br>Scrapy是一个为了爬取网站数据，提取结构性数据而编写的应用框架<br>多线程、异步</p>
<p>架构图&amp;运作流程<br>略</p>
<p>配置安装</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pip3 install Scrapy</span><br></pre></td></tr></table></figure></div>




<h4 id="入门案例"><a href="#入门案例" class="headerlink" title="入门案例"></a>入门案例</h4><p>入门案例</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">sh</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 进入项目目录中运行：</span></span><br><span class="line">scrapy startproject mySpider</span><br><span class="line"></span><br><span class="line">$ <span class="built_in">cd</span> mySpider</span><br><span class="line">mySpider        scrapy.cfg</span><br><span class="line"></span><br><span class="line"><span class="comment"># 目录结构</span></span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="comment"># 进入mySpider目录运行 生成爬虫</span></span><br><span class="line">scrapy genspider itcast <span class="string">"itcast.cn”</span></span><br><span class="line"><span class="string"># 会自动生成itcast.py</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string"># itcast.py</span></span><br><span class="line"><span class="string">...</span></span><br></pre></td></tr></table></figure></div>

<p>itcast.py</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">ItcastSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'itcast'</span> <span class="comment"># 爬虫名</span></span><br><span class="line">    allowed_domains = [<span class="string">'itcast.cn'</span>]  <span class="comment"># 允许爬的范围</span></span><br><span class="line">    start_urls = [<span class="string">'http://www.itcast.cn/channel/teacher.shtml'</span>]   <span class="comment"># 开始爬取的地址</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 继承</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="comment"># 处理start_urls对应的响应</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 每一个老师信息</span></span><br><span class="line">        li_list = response.xpath(<span class="string">"//div[@class='tea_con']//li"</span>)</span><br><span class="line">        <span class="keyword">for</span> li <span class="keyword">in</span> li_list:</span><br><span class="line">            item = &#123;&#125;</span><br><span class="line">            <span class="comment"># extract_first: 提取数据</span></span><br><span class="line">            item[<span class="string">"name"</span>] = li.xpath(<span class="string">".//h3/text()"</span>).extract_first()</span><br><span class="line">            item[<span class="string">"title"</span>] = li.xpath(<span class="string">".//h4/text()"</span>).extract_first()</span><br><span class="line">            <span class="comment"># 变成生成器、减小内存占用、将item传递给pipline</span></span><br><span class="line">            <span class="comment"># print(item)</span></span><br><span class="line">            <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure></div>

<p>go on</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">sh</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 启动</span></span><br><span class="line">scrapy crawl itcast</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">settings.py</span><br><span class="line"><span class="comment"># 设置日志等级</span></span><br><span class="line">LOG_LEVEL = <span class="string">"WARNING"</span></span><br><span class="line"><span class="comment"># 开启pipline</span></span><br><span class="line"><span class="comment"># 多个pipline，有处理优先级（距离引擎的远近）,越近越先处理</span></span><br><span class="line">ITEM_PIPELINES = &#123;</span><br><span class="line">   <span class="string">'mySpider.pipelines.MyspiderPipeline'</span>: 300,</span><br><span class="line">   <span class="string">'mySpider.pipelines.MyspiderPipeline1'</span>: 301,</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="comment"># pipelines.py</span></span><br><span class="line">...</span><br></pre></td></tr></table></figure></div>

<p>pipelines.py</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># Define your item pipelines here</span></span><br><span class="line"><span class="comment">#</span></span><br><span class="line"><span class="comment"># Don't forget to add your pipeline to the ITEM_PIPELINES setting</span></span><br><span class="line"><span class="comment"># See: https://doc.scrapy.org/en/latest/topics/item-pipeline.html</span></span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyspiderPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        item[<span class="string">"hello"</span>] = <span class="string">"world"</span></span><br><span class="line">        <span class="comment"># pipline必须return传递item</span></span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">MyspiderPipeline1</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        print(item)</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure></div>





<p><strong>关于迭代器、生成器</strong></p>
<p>迭代器：不用再将所有要迭代的数据都一次性缓存下来供后续依次读取，这样可以节省大量的存储（内存）空间</p>
<p>生成器(generator)：生成器是一类特殊的迭代器。将每次迭代返回数值的return换成了yield，此时新定义的函数便不再是函数，而是一个<strong>生成器</strong>了。简单来说：只要在def中有yield关键字的 就称为 生成器</p>
<p>yield关键字有两点作用：</p>
<ul>
<li>保存当前运行状态（断点），然后暂停执行，即将生成器（函数）挂起</li>
<li>将yield关键字后面表达式的值作为返回值返回，此时可以理解为起到了return的作用</li>
</ul>
<h4 id="关于日志"><a href="#关于日志" class="headerlink" title="关于日志"></a>关于日志</h4><p>多个spider都提交到pipeline，需要if判断区分</p>
<p>关于日志</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line">import logging</span><br><span class="line"></span><br><span class="line"># 设置日志输出样式</span><br><span class="line">logging.basicConfig(...)</span><br><span class="line"></span><br><span class="line">logger &#x3D; logging.getLogger(__name__)</span><br><span class="line"></span><br><span class="line">logger.warning(&quot;XX&quot;)</span><br><span class="line"></span><br><span class="line"># -----------------------</span><br><span class="line">settings.py</span><br><span class="line"># 设置日志保存位置</span><br><span class="line">LOG_FILE &#x3D; &#39;.&#x2F;log.log&#39;</span><br></pre></td></tr></table></figure></div>




<h4 id="实现翻页"><a href="#实现翻页" class="headerlink" title="实现翻页"></a>实现翻页</h4><p>hr.py</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="comment"># 爬招聘信息，存到mongodb</span></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">HrSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'hr'</span></span><br><span class="line">    allowed_domains = [<span class="string">'tencent.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://hr.tencent.com/position.php'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        tr_list = response.xpath(<span class="string">"//table[@class='tablelist']/tr"</span>)[<span class="number">1</span>:<span class="number">-1</span>]</span><br><span class="line">        <span class="keyword">for</span> tr <span class="keyword">in</span> tr_list:</span><br><span class="line">            item = &#123;&#125;</span><br><span class="line">            item[<span class="string">"title"</span>] = tr.xpath(<span class="string">"./td[1]/a/text()"</span>).extract_first()</span><br><span class="line">            item[<span class="string">"position"</span>] = tr.xpath(<span class="string">"./td[2]/text()"</span>).extract_first()</span><br><span class="line">            item[<span class="string">"publish_date"</span>] = tr.xpath(<span class="string">"./td[5]/text()"</span>).extract_first()</span><br><span class="line">            <span class="keyword">yield</span> item</span><br><span class="line">        <span class="comment">#找到下一页的url地址</span></span><br><span class="line">        next_url = response.xpath(<span class="string">"//a[@id='next']/@href"</span>).extract_first()</span><br><span class="line">        <span class="keyword">if</span> next_url != <span class="string">"javascript:;"</span>:</span><br><span class="line">            next_url = <span class="string">"http://hr.tencent.com/"</span> +next_url</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(</span><br><span class="line">                next_url,</span><br><span class="line">                callback=self.parse,	<span class="comment"># 新请求使用哪个处理逻辑</span></span><br><span class="line">                <span class="comment"># meta = &#123;"item":item&#125;</span></span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="comment"># def parse1(self,response):</span></span><br><span class="line">    <span class="comment">#     response.meta["item"]</span></span><br></pre></td></tr></table></figure></div>



<p>settings.py</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">USER_AGENT = <span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_13_2) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/63.0.3239.132 Safari/537.36'</span></span><br></pre></td></tr></table></figure></div>



<p>piplines.py</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> pymongo <span class="keyword">import</span> MongoClient</span><br><span class="line"><span class="keyword">from</span> tencent.items <span class="keyword">import</span> TencentItem</span><br><span class="line"></span><br><span class="line">client = MongoClient()</span><br><span class="line">collection = client[<span class="string">"tencent"</span>][<span class="string">"hr"</span>]</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TencentPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        print(item)</span><br><span class="line">        collection.insert(item)</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure></div>



<p>else</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">scrapy.Request(url, callback, method, headers, body, cookies, meta, dont_filter=<span class="literal">False</span>)</span><br><span class="line"><span class="comment"># dont_filter : scrapy默认去重（请求过的url不会再请求）</span></span><br><span class="line"><span class="comment"># 如贴吧会更新数据（同一个url不同时间请求，数据不同），这时可将dont_filter=False</span></span><br></pre></td></tr></table></figure></div>

<h4 id="item"><a href="#item" class="headerlink" title="item"></a>item</h4><p>items.py</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TencentItem</span><span class="params">(scrapy.Item)</span>:</span></span><br><span class="line">    <span class="comment"># define the fields for your item here like:</span></span><br><span class="line">    title = scrapy.Field()</span><br><span class="line">    position = scrapy.Field()</span><br><span class="line">    publish_date = scrapy.Field()</span><br></pre></td></tr></table></figure></div>



<p>hr.py修改</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> tencent.items <span class="keyword">import</span> TencentItem</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> tr <span class="keyword">in</span> tr_list:</span><br><span class="line">    <span class="comment"># 使用定义好的item</span></span><br><span class="line">    item = TencentItem()</span><br><span class="line">    item[<span class="string">"title"</span>] = tr.xpath(<span class="string">"./td[1]/a/text()"</span>).extract_first()</span><br><span class="line">    item[<span class="string">"position"</span>] = tr.xpath(<span class="string">"./td[2]/text()"</span>).extract_first()</span><br><span class="line">    item[<span class="string">"publish_date"</span>] = tr.xpath(<span class="string">"./td[5]/text()"</span>).extract_first()</span><br><span class="line">    <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure></div>



<p>piplines.py修改</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">TencentPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        <span class="keyword">if</span> isinstance(item,TencentItem):</span><br><span class="line">            print(item)</span><br><span class="line">            <span class="comment"># item不是字典，需要转化</span></span><br><span class="line">            collection.insert(dict(item))</span><br><span class="line">        <span class="keyword">return</span> item</span><br></pre></td></tr></table></figure></div>



<p><strong>item使用案例 - 阳光政务平台爬虫</strong></p>
<p>实现翻页+请求详情页</p>
<p>yg.py</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> yangguang.items <span class="keyword">import</span> YangguangItem</span><br><span class="line"><span class="keyword">from</span> yangguang.settings <span class="keyword">import</span> MONGO_HOST</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">YgSpider</span><span class="params">(scrapy.Spider)</span>:</span></span><br><span class="line">    name = <span class="string">'yg'</span></span><br><span class="line">    allowed_domains = [<span class="string">'sun07691.com'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://wz.sun0769.com/index.php/question/questionType?type=4&amp;page=0'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        <span class="comment">#分组</span></span><br><span class="line">        tr_list = response.xpath(<span class="string">"//div[@class='greyframe']/table[2]/tr/td/table/tr"</span>)</span><br><span class="line">        <span class="keyword">for</span> tr <span class="keyword">in</span> tr_list:</span><br><span class="line">            item = YangguangItem()</span><br><span class="line">            item[<span class="string">"title"</span>] = tr.xpath(<span class="string">"./td[2]/a[@class='news14']/@title"</span>).extract_first()</span><br><span class="line">            item[<span class="string">"href"</span>] = tr.xpath(<span class="string">"./td[2]/a[@class='news14']/@href"</span>).extract_first()</span><br><span class="line">            item[<span class="string">"publish_date"</span>]=tr.xpath(<span class="string">"./td[last()]/text()"</span>).extract_first()</span><br><span class="line">			</span><br><span class="line">            <span class="comment"># item有些字段需要请求详情页</span></span><br><span class="line">            <span class="keyword">yield</span>  scrapy.Request(</span><br><span class="line">                item[<span class="string">"href"</span>],</span><br><span class="line">                callback=self.parse_detail,</span><br><span class="line">                meta = &#123;<span class="string">"item"</span>:item&#125;</span><br><span class="line">            )</span><br><span class="line">        <span class="comment">#翻页</span></span><br><span class="line">        next_url = response.xpath(<span class="string">"//a[text()='&gt;']/@href"</span>).extract_first()</span><br><span class="line">        <span class="keyword">if</span> next_url <span class="keyword">is</span> <span class="keyword">not</span> <span class="literal">None</span>:</span><br><span class="line">            <span class="keyword">yield</span> scrapy.Request(</span><br><span class="line">                next_url,</span><br><span class="line">                callback=self.parse</span><br><span class="line">            )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_detail</span><span class="params">(self,response)</span>:</span> <span class="comment">#处理详情页</span></span><br><span class="line">        item = response.meta[<span class="string">"item"</span>]</span><br><span class="line">        item[<span class="string">"content"</span>] = response.xpath(<span class="string">"//div[@class='c1 text14_2']//text()"</span>).extract()</span><br><span class="line">        item[<span class="string">"content_img"</span>] = response.xpath(<span class="string">"//div[@class='c1 text14_2']//img/@src"</span>).extract()</span><br><span class="line">        item[<span class="string">"content_img"</span>] = [<span class="string">"http://wz.sun0769.com"</span>+i <span class="keyword">for</span> i <span class="keyword">in</span> item[<span class="string">"content_img"</span>]]</span><br><span class="line">        <span class="comment"># print(item)</span></span><br><span class="line">        <span class="keyword">yield</span> item</span><br></pre></td></tr></table></figure></div>



<p>piplines.py</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">from</span> yangguang.settings <span class="keyword">import</span> MONGO_HOST</span><br><span class="line"><span class="keyword">from</span> pymongo <span class="keyword">import</span> MongoClient</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">YangguangPipeline</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">        <span class="comment"># spider.hello = "world"</span></span><br><span class="line">        client = MongoClient()</span><br><span class="line">        self.collection = client[<span class="string">"test"</span>][<span class="string">"test"</span>]</span><br><span class="line">	</span><br><span class="line">    <span class="comment"># 保存到mongo</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_item</span><span class="params">(self, item, spider)</span>:</span></span><br><span class="line">        <span class="comment"># </span></span><br><span class="line">        spider.settings.get(<span class="string">"MONGO_HOST"</span>)</span><br><span class="line">        item[<span class="string">"content"</span>] = self.process_content(item[<span class="string">"content"</span>])</span><br><span class="line">        print(item)</span><br><span class="line"></span><br><span class="line">        self.collection.insert(dict(item))</span><br><span class="line">        <span class="keyword">return</span> item</span><br><span class="line">	</span><br><span class="line">    <span class="comment"># 做一些数据处理</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">process_content</span><span class="params">(self,content)</span>:</span></span><br><span class="line">        content = [re.sub(<span class="string">r"\xa0|\s"</span>,<span class="string">""</span>,i) <span class="keyword">for</span> i <span class="keyword">in</span> content]</span><br><span class="line">        content = [i <span class="keyword">for</span> i <span class="keyword">in</span> content <span class="keyword">if</span> len(i)&gt;<span class="number">0</span>] <span class="comment">#去除列表中的空字符串</span></span><br><span class="line">        <span class="keyword">return</span> content</span><br></pre></td></tr></table></figure></div>



<h3 id="scrapy深入"><a href="#scrapy深入" class="headerlink" title="scrapy深入"></a>scrapy深入</h3><h4 id="debug日志-amp-scrapy-shell-amp-settings-py-amp-pipline"><a href="#debug日志-amp-scrapy-shell-amp-settings-py-amp-pipline" class="headerlink" title="debug日志 &amp; scrapy shell &amp; settings.py &amp; pipline"></a>debug日志 &amp; scrapy shell &amp; settings.py &amp; pipline</h4><p>程序的debug日志信息</p>
<p>略</p>
<p>scrapy shell</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">Scrapy shell是一个交互终端，我们可以在未启动spider的情况下尝试及调试代码，也可以用来测试XPath表达式</span><br><span class="line"></span><br><span class="line">使用方法：</span><br><span class="line">	scrapy shell http://www.itcast.cn/channel/teacher.shtml</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">response.url：当前响应的url地址</span><br><span class="line">response.request.url：当前响应对应的请求的url地址</span><br><span class="line">response.headers：响应头</span><br><span class="line">response.body：响应体，也就是html代码，默认是byte类型</span><br><span class="line">response.requests.headers：当前响应的请求头</span><br></pre></td></tr></table></figure></div>



<p>settings.py</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 存放公共变量</span></span><br><span class="line">MONGO_HOST = <span class="string">"localhost"</span></span><br><span class="line"><span class="comment"># 在pipline里使用</span></span><br><span class="line">spider.settings.get(<span class="string">"MONGO_HOST"</span>)</span><br></pre></td></tr></table></figure></div>



<p>pipline</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 爬虫开启的的时候，仅执行一次</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">open_spider</span><span class="params">(self,spider)</span>:</span></span><br><span class="line">        <span class="comment"># spider.hello = "world"</span></span><br><span class="line">        client = MongoClient()</span><br><span class="line">        self.collection = client[<span class="string">"test"</span>][<span class="string">"test"</span>]</span><br><span class="line">        </span><br><span class="line"><span class="comment"># 爬虫关闭的的时候，仅执行一次      </span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">close_spider</span></span></span><br></pre></td></tr></table></figure></div>



<h4 id="综合案例-苏宁图书爬虫"><a href="#综合案例-苏宁图书爬虫" class="headerlink" title="综合案例-苏宁图书爬虫"></a>综合案例-苏宁图书爬虫</h4><h4 id="crawlspider"><a href="#crawlspider" class="headerlink" title="crawlspider"></a>crawlspider</h4><p>crowspider</p>
<p>启动项目</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">sh</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight sh"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">$ scrapy startproject circ</span><br><span class="line">$ <span class="built_in">cd</span> circ</span><br><span class="line">$ scrapy genspider -t crawl cf bxjg.circ.gov.cn</span><br></pre></td></tr></table></figure></div>

<p>cf.py</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">python</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="string">提取每一个详情页的某些字段</span></span><br><span class="line"><span class="string"></span></span><br><span class="line"><span class="string">"""</span></span><br><span class="line"><span class="comment"># -*- coding: utf-8 -*-</span></span><br><span class="line"><span class="keyword">import</span> scrapy</span><br><span class="line"><span class="keyword">from</span> scrapy.linkextractors <span class="keyword">import</span> LinkExtractor</span><br><span class="line"><span class="keyword">from</span> scrapy.spiders <span class="keyword">import</span> CrawlSpider, Rule</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">CfSpider</span><span class="params">(CrawlSpider)</span>:</span></span><br><span class="line">    name = <span class="string">'cf'</span></span><br><span class="line">    allowed_domains = [<span class="string">'bxjg.circ.gov.cn'</span>]</span><br><span class="line">    start_urls = [<span class="string">'http://bxjg.circ.gov.cn/web/site0/tab5240/module14430/page1.htm'</span>]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 定义提取url地址规则</span></span><br><span class="line">    rules = (</span><br><span class="line">        <span class="comment"># LinkExtractor：连接提取器，提取url地址</span></span><br><span class="line">        <span class="comment"># allow：通过正则表达式提取url</span></span><br><span class="line">        <span class="comment"># 提取后会交给父类parse函数发送请求，所以子类不能自定义parse函数</span></span><br><span class="line">        <span class="comment"># callback：提取后的url的response 会交给callback处理，callback可以为null</span></span><br><span class="line">        <span class="comment"># follow：当前url的响应，是否重新经过该Rule的规则来提取</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># /web/site0/tab5240/module14430/page3.htm</span></span><br><span class="line">        <span class="comment"># CrawlSpider会自动补充完整的url</span></span><br><span class="line">        Rule(LinkExtractor(allow=<span class="string">r'/web/site0/tab5240/info\d+\.htm'</span>), callback=<span class="string">'parse_item'</span>, follow=<span class="literal">False</span>),</span><br><span class="line">        Rule(LinkExtractor(allow=<span class="string">r'/web/site0/tab5240/module14430/page\d+\.htm'</span>), follow=<span class="literal">True</span>),</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">        <span class="comment"># Rule(LinkExtractor(allow=r'Items/'), callback='parse_item', follow=True),</span></span><br><span class="line">    )</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">parse_item</span><span class="params">(self, response)</span>:</span></span><br><span class="line">        item = &#123;&#125;</span><br><span class="line">        <span class="comment">#item['domain_id'] = response.xpath('//input[@id="sid"]/@value').get()</span></span><br><span class="line">        <span class="comment">#item['name'] = response.xpath('//div[@id="name"]').get()</span></span><br><span class="line">        <span class="comment">#item['description'] = response.xpath('//div[@id="description"]').get()</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># &lt;!--TitleStart--&gt;中国银行保险监督管理委员会行政处罚决定书(银保监罚决字〔2019〕2号) &lt;!--TitleEnd--&gt;</span></span><br><span class="line">        item[<span class="string">'title'</span>] = re.findall(<span class="string">"&lt;!--TitleStart--&gt;(.*?)&lt;!--TitleEnd--&gt;"</span>, response.body.decode())[<span class="number">0</span>]</span><br><span class="line">        <span class="comment"># 发布时间：2019-03-18</span></span><br><span class="line">        item[<span class="string">'publish_date'</span>] = re.findall(<span class="string">"发布时间：(\d&#123;4&#125;-\d&#123;2&#125;-\d&#123;2&#125;)"</span>, response.body.decode())[<span class="number">0</span>]</span><br><span class="line"></span><br><span class="line">        print(item)</span><br></pre></td></tr></table></figure></div>

<p>else</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"># 运行</span><br><span class="line">$ scrapy crawl cf</span><br><span class="line"></span><br><span class="line">其他参数说明：</span><br><span class="line">略</span><br></pre></td></tr></table></figure></div>





</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Machine</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://machine4869.gitee.io/2019/03/21/20190321133211318/">https://machine4869.gitee.io/2019/03/21/20190321133211318/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://machine4869.gitee.io">哑舍</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/python%E7%88%AC%E8%99%AB/">python爬虫    </a></div><div class="post_share"><div class="social-share" data-image="/img/default_p4.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/wechat.png" alt="微信"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/alipay.jpg" alt="支付宝"><div class="post-qr-code__desc">支付宝</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2019/03/26/20190326162203290/"><img class="prev_cover lazyload" data-src="/img/default_p2.jpeg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>java设计模式-UML简述&amp;软件设计七大原则</span></div></a></div><div class="next-post pull_right"><a href="/2019/03/04/20190304105434006/"><img class="next_cover lazyload" data-src="/img/default_p2.jpeg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>MongoDB(by python)</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2019/02/28/20190228113234928/" title="python爬虫(2)-动态HTMl处理"><img class="relatedPosts_cover lazyload"data-src="/img/default_p8.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-02-28</div><div class="relatedPosts_title">python爬虫(2)-动态HTMl处理</div></div></a></div><div class="relatedPosts_item"><a href="/2019/02/20/20190220155214243/" title="python爬虫(1)-爬虫基础&数据提取"><img class="relatedPosts_cover lazyload"data-src="/img/default_p7.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-02-20</div><div class="relatedPosts_title">python爬虫(1)-爬虫基础&数据提取</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div class="vcomment" id="vcomment"></div><script src="https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js"></script><script>var notify = true == true ? true : false;
var verify = false == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;

window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'yPVvDIaWlODDhs0bbECwLIIp-gzGzoHsz',
  appKey:'VyOIa40LxnjURzW1HUCiwTpV',
  placeholder:'记得留下你的昵称及邮箱，以便收到答复~',
  avatar:'monsterid',
  guest_info:guest_info,
  pageSize:'10',
  lang:'zh-cn',
  recordIP: true
});</script></div></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2020 By Machine</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://machine4869.gitee.io/">blog</a>!</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">简</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script id="canvas_nest" color="215,215,215" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/canvas-nest.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>