<!DOCTYPE html><html lang="zh-CN" data-theme="light"><head><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5"><title>Hadoop-基础篇 | 哑舍</title><meta name="description" content="Hadoop-基础篇"><meta name="keywords" content="大数据"><meta name="author" content="Machine"><meta name="copyright" content="Machine"><meta name="format-detection" content="telephone=no"><link rel="shortcut icon" href="/img/cat2.ico"><link rel="preconnect" href="//cdn.jsdelivr.net"><link rel="preconnect" href="https://fonts.googleapis.com" crossorigin><link rel="preconnect" href="//busuanzi.ibruce.info"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Hadoop-基础篇"><meta name="twitter:description" content="Hadoop-基础篇"><meta name="twitter:image" content="https://machine4869.gitee.io/img/default_p2.jpeg"><meta property="og:type" content="article"><meta property="og:title" content="Hadoop-基础篇"><meta property="og:url" content="https://machine4869.gitee.io/2019/06/20/20190620122348137/"><meta property="og:site_name" content="哑舍"><meta property="og:description" content="Hadoop-基础篇"><meta property="og:image" content="https://machine4869.gitee.io/img/default_p2.jpeg"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><script src="https://cdn.jsdelivr.net/npm/js-cookie/dist/js.cookie.min.js"></script><script>const autoChangeMode = 'false'
var t = Cookies.get("theme");
if (autoChangeMode == '1'){
const isDarkMode = window.matchMedia("(prefers-color-scheme: dark)").matches
const isLightMode = window.matchMedia("(prefers-color-scheme: light)").matches
const isNotSpecified = window.matchMedia("(prefers-color-scheme: no-preference)").matches
const hasNoSupport = !isDarkMode && !isLightMode && !isNotSpecified

if (t === undefined){
  if (isLightMode) activateLightMode()
  else if (isDarkMode) activateDarkMode()
  else if (isNotSpecified || hasNoSupport){
    console.log('You specified no preference for a color scheme or your browser does not support it. I Schedule dark mode during night time.')
    now = new Date();
    hour = now.getHours();
    isNight = hour < 6 || hour >= 18
    isNight ? activateDarkMode() : activateLightMode()
}
} else if (t == 'light') activateLightMode()
else activateDarkMode()


} else if (autoChangeMode == '2'){
  now = new Date();
  hour = now.getHours();
  isNight = hour < 6 || hour >= 18
  if(t === undefined) isNight? activateDarkMode() : activateLightMode()
  else if (t === 'light') activateLightMode()
  else activateDarkMode() 
} else {
  if ( t == 'dark' ) activateDarkMode()
  else if ( t == 'light') activateLightMode()
}

function activateDarkMode(){
  document.documentElement.setAttribute('data-theme', 'dark')
  if (document.querySelector('meta[name="theme-color"]') !== null){
    document.querySelector('meta[name="theme-color"]').setAttribute('content','#000')
  }
}
function activateLightMode(){
  document.documentElement.setAttribute('data-theme', 'light')
  if (document.querySelector('meta[name="theme-color"]') !== null){
  document.querySelector('meta[name="theme-color"]').setAttribute('content','#fff')
  }
}</script><link rel="stylesheet" href="/css/index.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/font-awesome@latest/css/font-awesome.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.css"><link rel="canonical" href="https://machine4869.gitee.io/2019/06/20/20190620122348137/"><link rel="prev" title="知识点脑图汇总" href="https://machine4869.gitee.io/2019/06/20/20190620200819690/"><link rel="next" title="java设计模式-UML简述&amp;软件设计七大原则" href="https://machine4869.gitee.io/2019/03/26/20190326162203290/"><link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Titillium+Web"><script>var GLOBAL_CONFIG = { 
  root: '/',
  algolia: undefined,
  localSearch: {"path":"search.xml","languages":{"hits_empty":"找不到您查询的内容:${query}"}},
  translate: {"defaultEncoding":2,"translateDelay":0,"cookieDomain":"https://machine4869.gitee.io/","msgToTraditionalChinese":"繁","msgToSimplifiedChinese":"简"},
  copy: {
    success: '复制成功',
    error: '复制错误',
    noSupport: '浏览器不支持'
  },
  bookmark: {
    title: 'Snackbar.bookmark.title',
    message_prev: '按',
    message_next: '键将本页加入书签'
  },
  runtime_unit: '天',
  runtime: true,
  copyright: undefined,
  ClickShowText: undefined,
  medium_zoom: false,
  fancybox: true,
  Snackbar: {"bookmark":{"title":"Snackbar.bookmark.title","message_prev":"按","message_next":"键将本页加入书签"},"chs_to_cht":"你已切换为繁体","cht_to_chs":"你已切换为简体","day_to_night":"你已切换为深色模式","night_to_day":"你已切换为浅色模式","bgLight":"#49b1f5","bgDark":"#2d3035","position":"bottom-left"},
  baiduPush: false,
  isHome: false,
  isPost: true
  
}</script><meta name="generator" content="Hexo 4.2.0"></head><body><header> <div id="page-header"><span class="pull_left" id="blog_name"><a class="blog_title" id="site-name" href="/">哑舍</a></span><span class="toggle-menu pull_right close"><a class="site-page"><i class="fa fa-bars fa-fw" aria-hidden="true"></i></a></span><span class="pull_right menus"><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 更多</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 豆瓣电影</span></a></li><li><a class="site-page" href="/photos/"><i class="fa-fw fa fa-picture-o"></i><span> 照片墙</span></a></li></ul></div></div></span><span class="pull_right" id="search_button"><a class="site-page social-icon search"><i class="fa fa-search fa-fw"></i><span> 搜索</span></a></span></div></header><div id="mobile-sidebar"><div id="menu_mask"></div><div id="mobile-sidebar-menus"><div class="mobile_author_icon"><img class="avatar-img" src="/img/head.jpg" onerror="onerror=null;src='/img/friend_404.gif'" alt="avatar"></div><div class="mobile_post_data"><div class="mobile_data_item is-center"><div class="mobile_data_link"><a href="/archives/"><div class="headline">文章</div><div class="length_num">134</div></a></div></div><div class="mobile_data_item is-center">      <div class="mobile_data_link"><a href="/tags/"><div class="headline">标签</div><div class="length_num">27</div></a></div></div><div class="mobile_data_item is-center">     <div class="mobile_data_link"><a href="/categories/"><div class="headline">分类</div><div class="length_num">45</div></a></div></div></div><hr><div class="menus_items"><div class="menus_item"><a class="site-page" href="/"><i class="fa-fw fa fa-home"></i><span> 首页</span></a></div><div class="menus_item"><a class="site-page" href="/archives/"><i class="fa-fw fa fa-archive"></i><span> 时间轴</span></a></div><div class="menus_item"><a class="site-page" href="/tags/"><i class="fa-fw fa fa-tags"></i><span> 标签</span></a></div><div class="menus_item"><a class="site-page" href="/categories/"><i class="fa-fw fa fa-folder-open"></i><span> 分类</span></a></div><div class="menus_item"><a class="site-page" href="/link/"><i class="fa-fw fa fa-link"></i><span> 友链</span></a></div><div class="menus_item"><a class="site-page" href="/about/"><i class="fa-fw fa fa-heart"></i><span> 关于</span></a></div><div class="menus_item"><a class="site-page"><i class="fa-fw fa fa-list" aria-hidden="true"></i><span> 更多</span><i class="fa fa-chevron-down menus-expand" aria-hidden="true"></i></a><ul class="menus_item_child"><li><a class="site-page" href="/music/"><i class="fa-fw fa fa-music"></i><span> 音乐</span></a></li><li><a class="site-page" href="/movies/"><i class="fa-fw fa fa-film"></i><span> 豆瓣电影</span></a></li><li><a class="site-page" href="/photos/"><i class="fa-fw fa fa-picture-o"></i><span> 照片墙</span></a></li></ul></div></div></div><div id="mobile-sidebar-toc"><div class="toc_mobile_headline">目录</div><div class="sidebar-toc__content"><ol class="toc_mobile_items"><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#简介"><span class="toc_mobile_items-number">1.</span> <span class="toc_mobile_items-text">简介</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#第1章-初识Hadoop"><span class="toc_mobile_items-number">2.</span> <span class="toc_mobile_items-text">第1章 初识Hadoop</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#1-1-Hadoop大数据平台架构与实践"><span class="toc_mobile_items-number">2.1.</span> <span class="toc_mobile_items-text">1-1 Hadoop大数据平台架构与实践</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#1-2-Hadoop的前世今生"><span class="toc_mobile_items-number">2.2.</span> <span class="toc_mobile_items-text">1-2 Hadoop的前世今生</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#1-3-Hadoop的功能与优势"><span class="toc_mobile_items-number">2.3.</span> <span class="toc_mobile_items-text">1-3 Hadoop的功能与优势</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#1-4-Hadoop生态系统及版本"><span class="toc_mobile_items-number">2.4.</span> <span class="toc_mobile_items-text">1-4 Hadoop生态系统及版本</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#第2章-Hadoop安装"><span class="toc_mobile_items-number">3.</span> <span class="toc_mobile_items-text">第2章 Hadoop安装</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#2-4-安装小结"><span class="toc_mobile_items-number">3.1.</span> <span class="toc_mobile_items-text">2-4 安装小结</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#第3章-Hadoop的核心-HDFS简介"><span class="toc_mobile_items-number">4.</span> <span class="toc_mobile_items-text">第3章 Hadoop的核心-HDFS简介</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#3-1-HDFS基本概念"><span class="toc_mobile_items-number">4.1.</span> <span class="toc_mobile_items-text">3-1 HDFS基本概念</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#3-2-数据管理策略"><span class="toc_mobile_items-number">4.2.</span> <span class="toc_mobile_items-text">3-2 数据管理策略</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#3-3-HDFS中文件的读写操作"><span class="toc_mobile_items-number">4.3.</span> <span class="toc_mobile_items-text">3-3 HDFS中文件的读写操作</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#3-4-HDFS特点"><span class="toc_mobile_items-number">4.4.</span> <span class="toc_mobile_items-text">3-4 HDFS特点</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#3-5-HDFS使用"><span class="toc_mobile_items-number">4.5.</span> <span class="toc_mobile_items-text">3-5 HDFS使用</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#第4章-Hadoop的核心-MapReduce"><span class="toc_mobile_items-number">5.</span> <span class="toc_mobile_items-text">第4章 Hadoop的核心-MapReduce</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#4-1-MapReduce的原理"><span class="toc_mobile_items-number">5.1.</span> <span class="toc_mobile_items-text">4-1 MapReduce的原理</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#4-2-MapReduce的运行流程"><span class="toc_mobile_items-number">5.2.</span> <span class="toc_mobile_items-text">4-2 MapReduce的运行流程</span></a></li></ol></li><li class="toc_mobile_items-item toc_mobile_items-level-1"><a class="toc_mobile_items-link" href="#第5章-开发Hadoop应用程序"><span class="toc_mobile_items-number">6.</span> <span class="toc_mobile_items-text">第5章 开发Hadoop应用程序</span></a><ol class="toc_mobile_items-child"><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#5-1～5-3-WordCount单词计数"><span class="toc_mobile_items-number">6.1.</span> <span class="toc_mobile_items-text">5-1～5-3 WordCount单词计数</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#5-4-5-5-利用MapReduce进行排序"><span class="toc_mobile_items-number">6.2.</span> <span class="toc_mobile_items-text">5-4~5-5 利用MapReduce进行排序</span></a></li><li class="toc_mobile_items-item toc_mobile_items-level-2"><a class="toc_mobile_items-link" href="#5-6-课程总结"><span class="toc_mobile_items-number">6.3.</span> <span class="toc_mobile_items-text">5-6 课程总结</span></a></li></ol></li></ol></div></div></div><div id="body-wrap"><i class="fa fa-arrow-right" id="toggle-sidebar" aria-hidden="true">     </i><div class="auto_open" id="sidebar"><div class="sidebar-toc"><div class="sidebar-toc__title">目录</div><div class="sidebar-toc__progress"><span class="progress-notice">你已经读了</span><span class="progress-num">0</span><span class="progress-percentage">%</span><div class="sidebar-toc__progress-bar">     </div></div><div class="sidebar-toc__content"><ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link" href="#简介"><span class="toc-number">1.</span> <span class="toc-text">简介</span></a></li><li class="toc-item toc-level-1"><a class="toc-link" href="#第1章-初识Hadoop"><span class="toc-number">2.</span> <span class="toc-text">第1章 初识Hadoop</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#1-1-Hadoop大数据平台架构与实践"><span class="toc-number">2.1.</span> <span class="toc-text">1-1 Hadoop大数据平台架构与实践</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-2-Hadoop的前世今生"><span class="toc-number">2.2.</span> <span class="toc-text">1-2 Hadoop的前世今生</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-3-Hadoop的功能与优势"><span class="toc-number">2.3.</span> <span class="toc-text">1-3 Hadoop的功能与优势</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#1-4-Hadoop生态系统及版本"><span class="toc-number">2.4.</span> <span class="toc-text">1-4 Hadoop生态系统及版本</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#第2章-Hadoop安装"><span class="toc-number">3.</span> <span class="toc-text">第2章 Hadoop安装</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#2-4-安装小结"><span class="toc-number">3.1.</span> <span class="toc-text">2-4 安装小结</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#第3章-Hadoop的核心-HDFS简介"><span class="toc-number">4.</span> <span class="toc-text">第3章 Hadoop的核心-HDFS简介</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#3-1-HDFS基本概念"><span class="toc-number">4.1.</span> <span class="toc-text">3-1 HDFS基本概念</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-2-数据管理策略"><span class="toc-number">4.2.</span> <span class="toc-text">3-2 数据管理策略</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-3-HDFS中文件的读写操作"><span class="toc-number">4.3.</span> <span class="toc-text">3-3 HDFS中文件的读写操作</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-4-HDFS特点"><span class="toc-number">4.4.</span> <span class="toc-text">3-4 HDFS特点</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#3-5-HDFS使用"><span class="toc-number">4.5.</span> <span class="toc-text">3-5 HDFS使用</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#第4章-Hadoop的核心-MapReduce"><span class="toc-number">5.</span> <span class="toc-text">第4章 Hadoop的核心-MapReduce</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#4-1-MapReduce的原理"><span class="toc-number">5.1.</span> <span class="toc-text">4-1 MapReduce的原理</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#4-2-MapReduce的运行流程"><span class="toc-number">5.2.</span> <span class="toc-text">4-2 MapReduce的运行流程</span></a></li></ol></li><li class="toc-item toc-level-1"><a class="toc-link" href="#第5章-开发Hadoop应用程序"><span class="toc-number">6.</span> <span class="toc-text">第5章 开发Hadoop应用程序</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#5-1～5-3-WordCount单词计数"><span class="toc-number">6.1.</span> <span class="toc-text">5-1～5-3 WordCount单词计数</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-4-5-5-利用MapReduce进行排序"><span class="toc-number">6.2.</span> <span class="toc-text">5-4~5-5 利用MapReduce进行排序</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#5-6-课程总结"><span class="toc-number">6.3.</span> <span class="toc-text">5-6 课程总结</span></a></li></ol></li></ol></div></div></div><main id="content-outer"><div id="top-container" style="background-image: url(/img/default_p2.jpeg)"><div id="post-info"><div id="post-title"><div class="posttitle">Hadoop-基础篇</div></div><div id="post-meta"><time class="post-meta__date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 发表于 2019-06-20<span class="post-meta__separator">|</span><i class="fa fa-history fa-fw" aria-hidden="true"></i> 更新于 2019-11-28</time><span class="post-meta__separator">|</span><span><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E5%BC%8F/">大数据分布式</a><i class="fa fa-angle-right fa-fw" aria-hidden="true"></i><i class="fa fa-inbox post-meta__icon fa-fw" aria-hidden="true"></i><a class="post-meta__categories" href="/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%88%86%E5%B8%83%E5%BC%8F/Hadoop/">Hadoop</a></span><div class="post-meta-wordcount"><i class="fa fa-file-word-o post-meta__icon fa-fw" aria-hidden="true"></i><span>字数总计:</span><span class="word-count">3.5k</span><span class="post-meta__separator">|</span><i class="fa fa-clock-o post-meta__icon fa-fw" aria-hidden="true"></i><span>阅读时长: 13 分钟</span><div class="post-meta-pv-cv"><span class="post-meta__separator">|</span><span><i class="fa fa-eye post-meta__icon fa-fw" aria-hidden="true"> </i>阅读量:</span><span id="busuanzi_value_page_pv"></span><span class="post-meta__separator">|</span><i class="fa fa-comments-o post-meta__icon fa-fw" aria-hidden="true"></i><span>评论数:</span><a href="/2019/06/20/20190620122348137/#post-comment" itemprop="discussionUrl"><span class="valine-comment-count comment-count" data-xid="/2019/06/20/20190620122348137/" itemprop="commentCount"></span></a></div></div></div></div></div><div class="layout layout_post" id="content-inner">   <article id="post"><div class="article-container" id="post-content"><blockquote>
<p>参考：</p>
<ul>
<li>imooc <a href="https://www.imooc.com/learn/391" target="_blank" rel="noopener">认识Hadoop–基础篇</a></li>
<li>笔记 <a href="https://hankin2015.github.io/2018/01/06/20180106Hadoop/" target="_blank" rel="noopener">Hadoop大数据平台架构与实践–基础篇</a></li>
<li>我的代码：</li>
</ul>
</blockquote>
<h1 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h1><p>大数据时代已经到来，越来越多的行业面临着大量数据需要存储以及分析的挑战。Hadoop，作为一个开源的分布式并行处理平台，以其高扩展、高效率、高可靠等优点，得到越来越广泛的应用。本课旨在培养学员理解Hadoop的架构设计以及掌握Hadoop的运用能力。</p>
<h1 id="第1章-初识Hadoop"><a href="#第1章-初识Hadoop" class="headerlink" title="第1章 初识Hadoop"></a>第1章 初识Hadoop</h1><h2 id="1-1-Hadoop大数据平台架构与实践"><a href="#1-1-Hadoop大数据平台架构与实践" class="headerlink" title="1-1 Hadoop大数据平台架构与实践"></a>1-1 Hadoop大数据平台架构与实践</h2><p>学习目标：<br>掌握大数据存储与处理技术的原理（理论）<br>掌握Hadoop的使用和开发能力<br>学习建议：<br>《Hadoop技术详解》《Hadoop权威指南》<br>Linux命令、Java编程基础</p>
<p>1.大数据的相关概念<br>2.Hadoop的架构和运行机制<br>3.实战：Hadoop的安装和配置<br>4.实战：Hadoop开发</p>
<h2 id="1-2-Hadoop的前世今生"><a href="#1-2-Hadoop的前世今生" class="headerlink" title="1-2 Hadoop的前世今生"></a>1-2 Hadoop的前世今生</h2><p>系统瓶颈：存储容量 读写速率 运行效率<br>google 提出三大关键技术mapreduce Bigtable GFS<br>革命性变化：<br>1、降低成本，普通PC集群；<br>2、硬件故障是常态，利用软件保证高可靠性；<br>3、简化并行计算，无须同步和数据交换</p>
<p>hadoop:是模拟谷歌的分布式的开源实现，其作用是降低成本，可容错，高效计算<br>容错性：硬件故障是常态，通过软件来保证可靠性</p>
<h2 id="1-3-Hadoop的功能与优势"><a href="#1-3-Hadoop的功能与优势" class="headerlink" title="1-3 Hadoop的功能与优势"></a>1-3 Hadoop的功能与优势</h2><p>Hadoop=分布式存储+分布式计算<br>包括两个核心组成：<br>HDFS：分布式文件系统，存储海量的数据<br>MapReduce：并行处理框架，实现任务分解和调度。</p>
<p>优势：高扩展、低成本<br>Hadoop可以用来搭建大型数据仓库，PB级数据的存储、处理、分析、统计等业务</p>
<h2 id="1-4-Hadoop生态系统及版本"><a href="#1-4-Hadoop生态系统及版本" class="headerlink" title="1-4 Hadoop生态系统及版本"></a>1-4 Hadoop生态系统及版本</h2><p>Hadoop不仅包括HDFS和MapReduce，还包括一次额开源工具。比如：<br>HIVE，本意是小蜜蜂，轻盈。<br>HBASE，存储结构化数据的分布式数据库。区别于HDFS的一点是，HABASE提供数据的随机读写和实时访问，实现对表数据的读写功能。<br>zookeeper，动物管理员。 监控Hadoop集群里面每个节点的状态，管理整个集群的配置，维护节点之家数据的（一次？依次）性</p>
<p>hive使sql转成一个hadoop任务去执行，降低hadoop的门槛。<br>hive(sql语句转换工具) habse(结构型数据，随机写入和实时读取) zookeeper(监控个节点使用、配置)。<br>habase存储结构化数据的分布式数据库，放弃事务特性，追求更高的扩展。habase提供数据的随机读写和实时访问，实现对表数据的读写功能。<br>zookeeper监控hadoop每个节点的状态，管理集群配置，维护节点间数据的一致性。<br>zookeeper的作用:<br>1）监控hadoop每个节点的状态<br>2）管理整个集群的配置<br>3）维护节点间数据的一致性</p>
<p>hadoop生态系统：<br>1.hdfs<br>2.mapreduce<br>3.相关开源工具：<br>（1）hive：将简单的sql语句转化为hadoop任务，降低使用hadoop的门槛<br>（2）HBASE：区别于传统数据库：存储结构化数据的分布式数据库，放弃事务特性，追求更高的扩展，它提供数据的随机读写和实时访问，实现对表数据的读写功能<br>（3）zookeeper:监控Hadoop集群里的每个节点的状态，管理整个集群的配置，维护数据节点之间的一致性<br>Hadoop版本最高2.6，初学者建议1.2（ver1.2-稳定）</p>
<h1 id="第2章-Hadoop安装"><a href="#第2章-Hadoop安装" class="headerlink" title="第2章 Hadoop安装"></a>第2章 Hadoop安装</h1><h2 id="2-4-安装小结"><a href="#2-4-安装小结" class="headerlink" title="2-4 安装小结"></a>2-4 安装小结</h2><p>修改4个配置文件<br>(a) 修改hadoop-env.sh,设置JAVA_HOME<br>(b) 修改core-site.xml,设置hadoop.tmp.dir, dfs.name.dir, fs.default.name<br>(c) 修改mapred-site.xml,设置mapred.job.tracker<br>(d) 修改hdfs-site.xml,设置dfs.data.dir</p>
<p>hadoop安装步骤：<br>1、安装JDK:apt-get install openjdk-7-jdk；<br>2、设置环境变量：JAVA_HOME、JRE_HOME、CLASSPATH、PATH（在/etc/profile）<br>3、下载hadoop安装包并解压到指定目录下；<br>4、设置环境变量：HADOOP_HOME、PATH（在/etc/profile）<br>5、修改相关配置文件$HADOOP_HOME/conf：<br>​    1）修改hadoop-env.sh，设置JAVA_HOME；<br>​    2）修改core-site.xml，设置hadoop.tmp.dir、dfs.name.dir、fs.default.name；<br>​    3）修改mapred-site.xml，设置mapred.job.tracker；<br>​    4）修改hdfs-site.xml，设置dfs.data.dir；<br>6、格式化：hadoop namenode -format；<br>7、启动：start-all.sh<br>8、检查：jps</p>
<h1 id="第3章-Hadoop的核心-HDFS简介"><a href="#第3章-Hadoop的核心-HDFS简介" class="headerlink" title="第3章 Hadoop的核心-HDFS简介"></a>第3章 Hadoop的核心-HDFS简介</h1><h2 id="3-1-HDFS基本概念"><a href="#3-1-HDFS基本概念" class="headerlink" title="3-1 HDFS基本概念"></a>3-1 HDFS基本概念</h2><p>HDFS的文件被分成快进行存储<br>HDFS块的默认大小64MB<br>块是文件村春处理的逻辑单元</p>
<p>nameNode 是管理节点，用来读取元数据的<br>DataNode是数据节点，用来存储数据的</p>
<p>HDFS——文件系统<br>MapReduce——并行计算框架</p>
<p>namenode是管理节点，存放文件元数据，元数据包括两部分：</p>
<ol>
<li>文件与数据块的映射表</li>
<li>数据块与数据节点的映射表</li>
</ol>
<p><a href="/2019/06/20/20190620122348137/5a3b288900016b4b12800720.jpg" data-fancybox="group" data-caption="5a3b288900016b4b12800720" class="fancybox"><img alt="5a3b288900016b4b12800720" title="5a3b288900016b4b12800720" data-src="/2019/06/20/20190620122348137/5a3b288900016b4b12800720.jpg" class="lazyload"></a> </p>
<h2 id="3-2-数据管理策略"><a href="#3-2-数据管理策略" class="headerlink" title="3-2 数据管理策略"></a>3-2 数据管理策略</h2><p>hdf数据管理策略：</p>
<ol>
<li>hdfs是采用master-slave的模式关管理文件，即一个master(namenade:保存datanode的一些基本信息和元数据)和多个slave(datanode:真正的存贮单元，里面存储了真实数据)</li>
<li>hdfs默认保存三份文件，有两份保存在同一台机器上，另外一份（备份文件）保存到另外一台机器上，确保当一台机器挂了时能保存数据的存在</li>
<li>namenade也有一个备用节点：Secondary NameNode,当namenode挂了时secondaryNameNode就变为nameNode的角色进行管理数据</li>
<li>datandoe会采用心跳的方式时不时的想namenode报告自己的基本信息，比如网络是否正常，运行是否正确常。</li>
</ol>
<h2 id="3-3-HDFS中文件的读写操作"><a href="#3-3-HDFS中文件的读写操作" class="headerlink" title="3-3 HDFS中文件的读写操作"></a>3-3 HDFS中文件的读写操作</h2><p><a href="/2019/06/20/20190620122348137/12617-20170308123104828-132826254.jpg" data-fancybox="group" data-caption="12617-20170308123104828-132826254" class="fancybox"><img alt="12617-20170308123104828-132826254" title="12617-20170308123104828-132826254" data-src="/2019/06/20/20190620122348137/12617-20170308123104828-132826254.jpg" class="lazyload"></a> </p>
<p>客户端发出读请求，namenode根据元数据返回给客户端，下载需要的block并组装</p>
<p>HDFS读取文件的流程：</p>
<p>（1）客户端向namenode发起读文件请求，把文件名，路径告诉namenode；</p>
<p>（2）namenode查询元数据，并把数据库返回客户端；</p>
<p>（3）此时客户端就明白文件包含哪些块，这些块在哪些datanode中可以找到；</p>
<p><a href="/2019/06/20/20190620122348137/12617-20170308123105109-1542248328.jpg" data-fancybox="group" data-caption="12617-20170308123105109-1542248328" class="fancybox"><img alt="12617-20170308123105109-1542248328" title="12617-20170308123105109-1542248328" data-src="/2019/06/20/20190620122348137/12617-20170308123105109-1542248328.jpg" class="lazyload"></a>  </p>
<p>HDFS写数据：首先将文件拆分为默认大小64M的块。通知NameNode，找到并返回可用的datanode信息，客户端写入一个后，其他的进行流水线复制。最后更新元数据。</p>
<p>HDFS写文件流程：</p>
<p>（1）客户端把文件拆分成固定大小64M的块，并通知namenode；</p>
<p>（2）namenode找到可用的datanode返回给客户端；</p>
<p>（3）客户端根据返回的datanode，对块进行写入</p>
<p>（4）通过流水线管道流水线复制</p>
<p>（5）更新元数据。告诉namenode已经完成了创建心的数据块。保证了namenode中的元数据都是最新的状态。</p>
<h2 id="3-4-HDFS特点"><a href="#3-4-HDFS特点" class="headerlink" title="3-4 HDFS特点"></a>3-4 HDFS特点</h2><p>1）数据冗余，硬件容错；</p>
<p>2）流式的数据访问，写一次，读多次。数据没办法修改，如果要修改只能把之前的数据删除，然后重新写入一份；</p>
<p>3）适合存储大文件，这是设计之初就这么考虑的，如果是大量的小文件的话，不适合，因为一个小文件也要存储元数据，此时NameNode的压力会非常大。</p>
<p>4）适合数据的批量读写，吞吐量高，不适合做交互式应用，低延迟很难满足；</p>
<p>5）支持顺序读写，不支持此多用户并发写相同文件；</p>
<h2 id="3-5-HDFS使用"><a href="#3-5-HDFS使用" class="headerlink" title="3-5 HDFS使用"></a>3-5 HDFS使用</h2><p>hadoop的几个常用命令来演示如何在hadoop中创建一个目录，然后上传一个文件，然后再下载一个文件。</p>
<p>大致都是：</p>
<p>hadoop fs -put filea.dat  input/</p>
<p>或者是get命令下载文件</p>
<p>或者是cat命令查看文件内容</p>
<p>或者是hdfsadmin命令来查看整个系统的一些统计信息。</p>
<h1 id="第4章-Hadoop的核心-MapReduce"><a href="#第4章-Hadoop的核心-MapReduce" class="headerlink" title="第4章 Hadoop的核心-MapReduce"></a>第4章 Hadoop的核心-MapReduce</h1><h2 id="4-1-MapReduce的原理"><a href="#4-1-MapReduce的原理" class="headerlink" title="4-1 MapReduce的原理"></a>4-1 MapReduce的原理</h2><p>所谓Map就是要将任务拆分成很多份，这里给了一个例子，有1000副牌，少了一张，然后要找出到底是少了哪一章。</p>
<p><a href="/2019/06/20/20190620122348137/12617-20170308123105359-963721942.jpg" data-fancybox="group" data-caption="12617-20170308123105359-963721942" class="fancybox"><img alt="12617-20170308123105359-963721942" title="12617-20170308123105359-963721942" data-src="/2019/06/20/20190620122348137/12617-20170308123105359-963721942.jpg" class="lazyload"></a> </p>
<p>然后又给了一个从日志中统计出访问此处最多的ip的例子，也都是类似的，先把日志分块，然后由不同的任务分别统计，然后再把他们的结果拿来合并，也就是Reduce了</p>
<h2 id="4-2-MapReduce的运行流程"><a href="#4-2-MapReduce的运行流程" class="headerlink" title="4-2 MapReduce的运行流程"></a>4-2 MapReduce的运行流程</h2><p>几个基本的概念：</p>
<ul>
<li><p>Job&amp;Task，比如上面的找出访问次数最多的任务就是一个Job，然后这个Job要完成的话要被分解为多个Task，放到不同的节点上去执行。Task又可以分为MapTask和ReduceTask</p>
</li>
<li><p>JobTracker，作业调度，分配任务并监控任务的执行进度，任务分配出去之后，TaskTracker每隔几秒钟要向JobTracker更新状态</p>
</li>
<li><p>TaskTracker，作业的执行</p>
</li>
</ul>
<p>这几个概念互相之间的关系如下图：</p>
<p><a href="/2019/06/20/20190620122348137/12617-20170308123105625-357060316.jpg" data-fancybox="group" data-caption="12617-20170308123105625-357060316" class="fancybox"><img alt="12617-20170308123105625-357060316" title="12617-20170308123105625-357060316" data-src="/2019/06/20/20190620122348137/12617-20170308123105625-357060316.jpg" class="lazyload"></a> </p>
<p>一般来说，TaskTracker就是分配在其数据所在的DataNode上，这样可以保证运行的效率最高，毕竟读取本机的磁盘总是更快的。这也是MapReduce的一个设计思想，用移动计算来避免移动数据。  </p>
<p><a href="/2019/06/20/20190620122348137/12617-20170308123105984-801660379.jpg" data-fancybox="group" data-caption="12617-20170308123105984-801660379" class="fancybox"><img alt="12617-20170308123105984-801660379" title="12617-20170308123105984-801660379" data-src="/2019/06/20/20190620122348137/12617-20170308123105984-801660379.jpg" class="lazyload"></a> </p>
<p>MapReduce的容错机制，</p>
<p>1）重复执行；也就是执行的过程中如果出错了，他会重复执行，但是重复了4次之后如果还出错，他就放弃了。</p>
<p> 2）推测执行，用于解决那种计算速度特别慢的情况，此时会新开一个任务，然后再看这两个任务谁先执行完。</p>
<h1 id="第5章-开发Hadoop应用程序"><a href="#第5章-开发Hadoop应用程序" class="headerlink" title="第5章 开发Hadoop应用程序"></a>第5章 开发Hadoop应用程序</h1><h2 id="5-1～5-3-WordCount单词计数"><a href="#5-1～5-3-WordCount单词计数" class="headerlink" title="5-1～5-3 WordCount单词计数"></a>5-1～5-3 WordCount单词计数</h2><p>需求：计算文件中出现每个单词的频数，输入结果按照字母顺序进行排序</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">byte		3</span><br><span class="line">hello 	3</span><br><span class="line">hadoop	4</span><br><span class="line">world		2</span><br></pre></td></tr></table></figure></div>



<p>思路：</p>
<p>map:切分<br>对每个词统计记1次</p>
<p>![屏幕快照 2019-08-14 下午2.47.39](20190620122348137/屏幕快照 2019-08-14 下午2.47.39.png)</p>
<p>reduce:合并<br>相同的key放在同一个节点</p>
<p>![屏幕快照 2019-08-14 下午2.48.16](20190620122348137/屏幕快照 2019-08-14 下午2.48.16.png)</p>
<p>代码实现</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">xml</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight xml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">dependency</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">groupId</span>&gt;</span>org.apache.hadoop<span class="tag">&lt;/<span class="name">groupId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">artifactId</span>&gt;</span>hadoop-client<span class="tag">&lt;/<span class="name">artifactId</span>&gt;</span></span><br><span class="line">  <span class="tag">&lt;<span class="name">version</span>&gt;</span>$&#123;hadoop.version&#125;<span class="tag">&lt;/<span class="name">version</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">dependency</span>&gt;</span></span><br></pre></td></tr></table></figure></div>



<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCount</span> </span>&#123;</span><br><span class="line">	<span class="comment">// 1 两个静态内部类</span></span><br><span class="line">	<span class="comment">// 2 继承Mapper，定义了输入输出格式&lt;key,value, key,value&gt;</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountMap</span> <span class="keyword">extends</span></span></span><br><span class="line"><span class="class">			<span class="title">Mapper</span>&lt;<span class="title">LongWritable</span>, <span class="title">Text</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 3 表示单词出现次数，初始为1次</span></span><br><span class="line">		<span class="keyword">private</span> <span class="keyword">final</span> IntWritable one = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</span><br><span class="line">		<span class="keyword">private</span> Text word = <span class="keyword">new</span> Text();</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 4 map切分操作</span></span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(LongWritable key, Text value, Context context)</span></span></span><br><span class="line"><span class="function">				<span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">			String line = value.toString();</span><br><span class="line">			StringTokenizer token = <span class="keyword">new</span> StringTokenizer(line);</span><br><span class="line"></span><br><span class="line">			<span class="comment">// 5 分词，发现一个词就写入</span></span><br><span class="line">			<span class="keyword">while</span> (token.hasMoreTokens()) &#123;</span><br><span class="line">				word.set(token.nextToken());</span><br><span class="line">				context.write(word, one);</span><br><span class="line">			&#125;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 继承Reducer，定义了输入输出格式&lt;key,value, key,value&gt;</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">WordCountReduce</span> <span class="keyword">extends</span></span></span><br><span class="line"><span class="class">			<span class="title">Reducer</span>&lt;<span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// reduce合并</span></span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(Text key, Iterable&lt;IntWritable&gt; values,</span></span></span><br><span class="line"><span class="function"><span class="params">				Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">			<span class="keyword">int</span> sum = <span class="number">0</span>;</span><br><span class="line">			<span class="comment">// &lt;hello, [1,1,1]&gt;  --&gt; &lt;hello, 3&gt;</span></span><br><span class="line">			<span class="keyword">for</span> (IntWritable val : values) &#123;</span><br><span class="line">				sum += val.get();</span><br><span class="line">			&#125;</span><br><span class="line">			context.write(key, <span class="keyword">new</span> IntWritable(sum));</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line"></span><br><span class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 配置作业</span></span><br><span class="line">		Job job = Job.getInstance(conf);</span><br><span class="line">		job.setJarByClass(WordCount<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		job.setJobName(<span class="string">"wordcount"</span>);</span><br><span class="line">		job.setOutputKeyClass(Text<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		job.setOutputValueClass(IntWritable<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		job.setMapperClass(WordCountMap<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		job.setReducerClass(WordCountReduce<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		job.setInputFormatClass(TextInputFormat<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		job.setOutputFormatClass(TextOutputFormat<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		</span><br><span class="line">    <span class="comment">// 文件输入和输出路径</span></span><br><span class="line">		FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(args[<span class="number">0</span>]));</span><br><span class="line">		FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(args[<span class="number">1</span>]));</span><br><span class="line"></span><br><span class="line">		job.waitForCompletion(<span class="keyword">true</span>);</span><br><span class="line">	&#125;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>



<p>输入文件如file1：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">hello world</span><br><span class="line">hello hadoop</span><br><span class="line">hadoop file system</span><br><span class="line">hadoop java api</span><br><span class="line">hello java</span><br></pre></td></tr></table></figure></div>



<p>部署到hadoop上执行：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><span class="line">- 打包成 WordCount.jar</span><br><span class="line">- 将file1 file2提交到fs文件系统里去</span><br><span class="line">$ hadoop fs -mkdir input_WordCount</span><br><span class="line">$ hadoop fs -put input&#x2F;* input_WordCount&#x2F;</span><br><span class="line">$ hadoop fs -ls</span><br><span class="line">$ hadoop fs -ls input_WordCount</span><br><span class="line">$ hadoop fs -cat input_WordCount&#x2F;file1</span><br><span class="line"></span><br><span class="line">- 提交任务</span><br><span class="line">$ hadoop jar WordCount.jar input_WordCount output_WordCount</span><br><span class="line">19&#x2F;08&#x2F;14 08:51:17 INFO mapred.JobClient:  map 0% reduce 0%</span><br><span class="line">19&#x2F;08&#x2F;14 08:51:29 INFO mapred.JobClient:  map 100% reduce 0%</span><br><span class="line">19&#x2F;08&#x2F;14 08:51:36 INFO mapred.JobClient:  map 100% reduce 33%</span><br><span class="line">19&#x2F;08&#x2F;14 08:51:38 INFO mapred.JobClient:  map 100% reduce 100%</span><br><span class="line"></span><br><span class="line">- 查看结果</span><br><span class="line">$ hadoop fs -ls output_WordCount</span><br><span class="line">$ hadoop fs -cat output_WordCount&#x2F;part-r-00000</span><br><span class="line">api	1</span><br><span class="line">file	3</span><br><span class="line">free	2</span><br><span class="line">hadoop	7</span><br><span class="line">hello	3</span><br><span class="line">home	1</span><br><span class="line">java	2</span><br><span class="line">new	2</span><br><span class="line">school	1</span><br><span class="line">system	1</span><br><span class="line">world	2</span><br></pre></td></tr></table></figure></div>



<h2 id="5-4-5-5-利用MapReduce进行排序"><a href="#5-4-5-5-利用MapReduce进行排序" class="headerlink" title="5-4~5-5 利用MapReduce进行排序"></a>5-4~5-5 利用MapReduce进行排序</h2><p>数据排序</p>
<p>思路：将数据按照大小区间分片，放到reduce进行排序</p>
<p>![屏幕快照 2019-08-14 下午5.02.13](20190620122348137/屏幕快照 2019-08-14 下午5.02.13.png) </p>
<p>输入样例：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">2</span><br><span class="line">32</span><br><span class="line">654</span><br><span class="line">32</span><br><span class="line">15</span><br><span class="line">756</span><br><span class="line">65223</span><br></pre></td></tr></table></figure></div>

<p>输出样例</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">1 2</span><br><span class="line">2 6</span><br><span class="line">3 15</span><br><span class="line">4 ...</span><br></pre></td></tr></table></figure></div>



<p>代码：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">java</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight java"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">public</span> <span class="class"><span class="keyword">class</span> <span class="title">Sort</span> </span>&#123;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 输出是&lt;IntWritable, IntWritable&gt;格式</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Map</span> <span class="keyword">extends</span></span></span><br><span class="line"><span class="class">			<span class="title">Mapper</span>&lt;<span class="title">Object</span>, <span class="title">Text</span>, <span class="title">IntWritable</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">private</span> <span class="keyword">static</span> IntWritable data = <span class="keyword">new</span> IntWritable();</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 读出文本的每一行，转化为整数作为key值放入，value随便放一个1</span></span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">map</span><span class="params">(Object key, Text value, Context context)</span></span></span><br><span class="line"><span class="function">				<span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line">			String line = value.toString();</span><br><span class="line"></span><br><span class="line">			data.set(Integer.parseInt(line));</span><br><span class="line"></span><br><span class="line">			context.write(data, <span class="keyword">new</span> IntWritable(<span class="number">1</span>));</span><br><span class="line"></span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Reduce</span> <span class="keyword">extends</span></span></span><br><span class="line"><span class="class">			<span class="title">Reducer</span>&lt;<span class="title">IntWritable</span>, <span class="title">IntWritable</span>, <span class="title">IntWritable</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">		<span class="keyword">private</span> <span class="keyword">static</span> IntWritable linenum = <span class="keyword">new</span> IntWritable(<span class="number">1</span>);</span><br><span class="line"></span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">void</span> <span class="title">reduce</span><span class="params">(IntWritable key, Iterable&lt;IntWritable&gt; values,</span></span></span><br><span class="line"><span class="function"><span class="params">				Context context)</span> <span class="keyword">throws</span> IOException, InterruptedException </span>&#123;</span><br><span class="line"></span><br><span class="line">			<span class="keyword">for</span> (IntWritable val : values) &#123;</span><br><span class="line"></span><br><span class="line">				context.write(linenum, key);</span><br><span class="line"></span><br><span class="line">				<span class="comment">// 行号+1，代表排序序号</span></span><br><span class="line">				linenum = <span class="keyword">new</span> IntWritable(linenum.get() + <span class="number">1</span>);</span><br><span class="line">			&#125;</span><br><span class="line"></span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">// 相当于自己定义reduce过程的分区策略(划分区间)，而不是使用默认的</span></span><br><span class="line">	<span class="comment">// 在每个区间排好序，合并之后就得到了最终结果</span></span><br><span class="line">	<span class="keyword">public</span> <span class="keyword">static</span> <span class="class"><span class="keyword">class</span> <span class="title">Partition</span> <span class="keyword">extends</span> <span class="title">Partitioner</span>&lt;<span class="title">IntWritable</span>, <span class="title">IntWritable</span>&gt; </span>&#123;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// numPartitions是分区数</span></span><br><span class="line">		<span class="comment">// 返回值是当前key属于哪个区间</span></span><br><span class="line">		<span class="meta">@Override</span></span><br><span class="line">		<span class="function"><span class="keyword">public</span> <span class="keyword">int</span> <span class="title">getPartition</span><span class="params">(IntWritable key, IntWritable value,</span></span></span><br><span class="line"><span class="function"><span class="params">				<span class="keyword">int</span> numPartitions)</span> </span>&#123;</span><br><span class="line">			<span class="keyword">int</span> MaxNumber = <span class="number">65223</span>;</span><br><span class="line">			<span class="keyword">int</span> bound = MaxNumber / numPartitions + <span class="number">1</span>;	<span class="comment">// 每个区间有多少个数</span></span><br><span class="line">			<span class="keyword">int</span> keynumber = key.get();</span><br><span class="line"></span><br><span class="line">			<span class="comment">// 扫描每个区间</span></span><br><span class="line">			<span class="keyword">for</span> (<span class="keyword">int</span> i = <span class="number">0</span>; i &lt; numPartitions; i++) &#123;</span><br><span class="line">				<span class="comment">// 如果当前key属于该区间，则返回分区号</span></span><br><span class="line">				<span class="keyword">if</span> (keynumber &lt; bound * i &amp;&amp; keynumber &gt;= bound * (i - <span class="number">1</span>))</span><br><span class="line">					<span class="keyword">return</span> i - <span class="number">1</span>;</span><br><span class="line">			&#125;</span><br><span class="line">			<span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">		&#125;</span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">	<span class="comment">/**</span></span><br><span class="line"><span class="comment">	 * <span class="doctag">@param</span> args</span></span><br><span class="line"><span class="comment">	 */</span></span><br><span class="line">	<span class="function"><span class="keyword">public</span> <span class="keyword">static</span> <span class="keyword">void</span> <span class="title">main</span><span class="params">(String[] args)</span> <span class="keyword">throws</span> Exception </span>&#123;</span><br><span class="line">		<span class="comment">// TODO Auto-generated method stub</span></span><br><span class="line">		Configuration conf = <span class="keyword">new</span> Configuration();</span><br><span class="line"></span><br><span class="line">		String[] otherArgs = <span class="keyword">new</span> GenericOptionsParser(conf, args)</span><br><span class="line">				.getRemainingArgs();</span><br><span class="line">		<span class="keyword">if</span> (otherArgs.length != <span class="number">2</span>) &#123;</span><br><span class="line">			System.err.println(<span class="string">"Usage WordCount &lt;int&gt; &lt;out&gt;"</span>);</span><br><span class="line">			System.exit(<span class="number">2</span>);</span><br><span class="line">		&#125;</span><br><span class="line"></span><br><span class="line">		<span class="comment">// 配置作业</span></span><br><span class="line">		Job job = Job.getInstance(conf, <span class="string">"Sort"</span>);</span><br><span class="line">		job.setJarByClass(Sort<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		job.setMapperClass(Map<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		job.setPartitionerClass(Partition<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		job.setReducerClass(Reduce<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		job.setOutputKeyClass(IntWritable<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		job.setOutputValueClass(IntWritable<span class="class">.<span class="keyword">class</span>)</span>;</span><br><span class="line">		FileInputFormat.addInputPath(job, <span class="keyword">new</span> Path(otherArgs[<span class="number">0</span>]));</span><br><span class="line">		FileOutputFormat.setOutputPath(job, <span class="keyword">new</span> Path(otherArgs[<span class="number">1</span>]));</span><br><span class="line">		System.exit(job.waitForCompletion(<span class="keyword">true</span>) ? <span class="number">0</span> : <span class="number">1</span>);</span><br><span class="line"></span><br><span class="line"><span class="comment">//		System.out.println("Sort...");</span></span><br><span class="line">	&#125;</span><br><span class="line"></span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure></div>

<p>最后输出结果：</p>
<div class="code-area-wrap"><div class="highlight-tools"><i class="fa fa-angle-down code-expand" aria-hidden="true"></i><div class="code_lang">Code</div><div class="copy-notice"></div><i class="fa fa-clipboard" aria-hidden="true"></i></div><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line">1	2</span><br><span class="line">2	6</span><br><span class="line">3	15</span><br><span class="line">4	22</span><br><span class="line">5	26</span><br><span class="line">6	32</span><br><span class="line">7	32</span><br><span class="line">8	54</span><br><span class="line">9	92</span><br><span class="line">10	650</span><br><span class="line">11	654</span><br><span class="line">12	756</span><br><span class="line">13	5956</span><br><span class="line">14	65223</span><br></pre></td></tr></table></figure></div>

<p>疑问：每个区间内部的排序是在哪里完成的？</p>
<h2 id="5-6-课程总结"><a href="#5-6-课程总结" class="headerlink" title="5-6 课程总结"></a>5-6 课程总结</h2><p>略</p>
</div></article><div class="post-copyright"><div class="post-copyright__author"><span class="post-copyright-meta">文章作者: </span><span class="post-copyright-info"><a href="mailto:undefined">Machine</a></span></div><div class="post-copyright__type"><span class="post-copyright-meta">文章链接: </span><span class="post-copyright-info"><a href="https://machine4869.gitee.io/2019/06/20/20190620122348137/">https://machine4869.gitee.io/2019/06/20/20190620122348137/</a></span></div><div class="post-copyright__notice"><span class="post-copyright-meta">版权声明: </span><span class="post-copyright-info">本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener">CC BY-NC-SA 4.0</a> 许可协议。转载请注明来自 <a href="https://machine4869.gitee.io">哑舍</a>！</span></div></div><div class="tag_share"><div class="post-meta__tag-list"><a class="post-meta__tags" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/">大数据    </a></div><div class="post_share"><div class="social-share" data-image="/img/default_p2.jpeg" data-sites="facebook,twitter,wechat,weibo,qq"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/social-share.js/dist/css/share.min.css"><script src="https://cdn.jsdelivr.net/npm/social-share.js/dist/js/social-share.min.js"></script></div></div><div class="post-reward"><a class="reward-button button--primary button--animated"> <i class="fa fa-qrcode"></i> 打赏<div class="reward-main"><ul class="reward-all"><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/wechat.png" alt="微信"><div class="post-qr-code__desc">微信</div></li><li class="reward-item"><img class="lazyload post-qr-code__img" src="/img/alipay.jpg" alt="支付宝"><div class="post-qr-code__desc">支付宝</div></li></ul></div></a></div><nav class="pagination_post" id="pagination"><div class="prev-post pull_left"><a href="/2019/06/20/20190620200819690/"><img class="prev_cover lazyload" data-src="/img/default_p10.jpeg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">上一篇</div><div class="prev_info"><span>知识点脑图汇总</span></div></a></div><div class="next-post pull_right"><a href="/2019/03/26/20190326162203290/"><img class="next_cover lazyload" data-src="/img/default_p2.jpeg" onerror="onerror=null;src='/img/404.jpg'"><div class="label">下一篇</div><div class="next_info"><span>java设计模式-UML简述&amp;软件设计七大原则</span></div></a></div></nav><div class="relatedPosts"><div class="relatedPosts_headline"><i class="fa fa-fw fa-thumbs-up" aria-hidden="true"></i><span> 相关推荐</span></div><div class="relatedPosts_list"><div class="relatedPosts_item"><a href="/2019/12/26/20191226144408846/" title="ELK-搜索引擎"><img class="relatedPosts_cover lazyload"data-src="/img/default_p1.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-12-26</div><div class="relatedPosts_title">ELK-搜索引擎</div></div></a></div><div class="relatedPosts_item"><a href="/2019/12/11/20191211154140441/" title="数据仓库-业务数据仓库"><img class="relatedPosts_cover lazyload"data-src="/img/default_p10.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-12-11</div><div class="relatedPosts_title">数据仓库-业务数据仓库</div></div></a></div><div class="relatedPosts_item"><a href="/2019/12/04/20191204140743901/" title="数据仓库-用户行为数据仓库"><img class="relatedPosts_cover lazyload"data-src="/img/default_p4.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-12-04</div><div class="relatedPosts_title">数据仓库-用户行为数据仓库</div></div></a></div><div class="relatedPosts_item"><a href="/2019/11/21/20191121155413741/" title="数据仓库-用户行为数据采集"><img class="relatedPosts_cover lazyload"data-src="/img/default_p1.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-11-21</div><div class="relatedPosts_title">数据仓库-用户行为数据采集</div></div></a></div><div class="relatedPosts_item"><a href="/2019/11/21/20191121140654751/" title="Ambari-Hadoop Web UI"><img class="relatedPosts_cover lazyload"data-src="/img/default_p7.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-11-21</div><div class="relatedPosts_title">Ambari-Hadoop Web UI</div></div></a></div><div class="relatedPosts_item"><a href="/2019/11/19/20191119151208934/" title="Kettle-ETL工具&数据抽取"><img class="relatedPosts_cover lazyload"data-src="/img/default_p5.jpeg"><div class="relatedPosts_main is-center"><div class="relatedPosts_date"><i class="fa fa-calendar fa-fw" aria-hidden="true"></i> 2019-11-19</div><div class="relatedPosts_title">Kettle-ETL工具&数据抽取</div></div></a></div></div><div class="clear_both"></div></div><hr><div id="post-comment"><div class="comment_headling"><i class="fa fa-comments fa-fw" aria-hidden="true"></i><span> 评论</span></div><div class="vcomment" id="vcomment"></div><script src="https://cdn.jsdelivr.net/npm/valine/dist/Valine.min.js"></script><script>var notify = true == true ? true : false;
var verify = false == true ? true : false;
var GUEST_INFO = ['nick','mail','link'];
var guest_info = 'nick,mail,link'.split(',').filter(function(item){
  return GUEST_INFO.indexOf(item) > -1
});
guest_info = guest_info.length == 0 ? GUEST_INFO :guest_info;

window.valine = new Valine({
  el:'#vcomment',
  notify:notify,
  verify:verify,
  appId:'yPVvDIaWlODDhs0bbECwLIIp-gzGzoHsz',
  appKey:'VyOIa40LxnjURzW1HUCiwTpV',
  placeholder:'记得留下你的昵称及邮箱，以便收到答复~',
  avatar:'monsterid',
  guest_info:guest_info,
  pageSize:'10',
  lang:'zh-cn',
  recordIP: true
});</script></div></div></main><footer id="footer" data-type="color"><div id="footer-wrap"><div class="copyright">&copy;2018 - 2020 By Machine</div><div class="framework-info"><span>驱动 </span><a href="http://hexo.io" target="_blank" rel="noopener"><span>Hexo</span></a><span class="footer-separator">|</span><span>主题 </span><a href="https://github.com/jerryc127/hexo-theme-butterfly" target="_blank" rel="noopener"><span>Butterfly</span></a></div><div class="footer_custom_text">Hi, welcome to my <a href="https://machine4869.gitee.io/">blog</a>!</div></div></footer></div><section class="rightside" id="rightside"><div id="rightside-config-hide"><i class="fa fa-book" id="readmode" title="阅读模式"></i><i class="fa fa-plus" id="font_plus" title="放大字体"></i><i class="fa fa-minus" id="font_minus" title="缩小字体"></i><a class="translate_chn_to_cht" id="translateLink" href="javascript:translatePage();" title="简繁转换" target="_self">简</a><i class="darkmode fa fa-moon-o" id="darkmode" title="夜间模式"></i></div><div id="rightside-config-show"><div id="rightside_config" title="设置"><i class="fa fa-cog" aria-hidden="true"></i></div><a id="to_comment" href="#post-comment" title="直达评论"><i class="scroll_to_comment fa fa-comments">  </i></a><i class="fa fa-list-ul close" id="mobile-toc-button" title="目录" aria-hidden="true"></i><i class="fa fa-arrow-up" id="go-up" title="回到顶部" aria-hidden="true"></i></div></section><script src="https://cdn.jsdelivr.net/npm/jquery@latest/dist/jquery.min.js"></script><script src="/js/utils.js"></script><script src="/js/main.js"></script><script src="/js/tw_cn.js"></script><script src="https://cdn.jsdelivr.net/npm/@fancyapps/fancybox@latest/dist/jquery.fancybox.min.js"></script><script src="https://cdn.jsdelivr.net/npm/node-snackbar/dist/snackbar.min.js"></script><script id="canvas_nest" color="215,215,215" opacity="0.7" zIndex="-1" count="99" mobile="false" src="https://cdn.jsdelivr.net/gh/jerryc127/butterfly_cdn@2.1.0/js/canvas-nest.js"></script><script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script><script src="https://cdn.jsdelivr.net/npm/instant.page@latest/instantpage.min.js" type="module"></script><script src="https://cdn.jsdelivr.net/npm/lazysizes@latest/lazysizes.min.js" async=""></script><div class="search-dialog" id="local-search"><div class="search-dialog__title" id="local-search-title">本地搜索</div><div id="local-input-panel"><div id="local-search-input"><div class="local-search-box"><input class="local-search-box--input" placeholder="搜索文章"></div></div></div><hr><div id="local-search-results"><div id="local-hits"></div><div id="local-stats"><div class="local-search-stats__hr" id="hr"><span>由</span> <a href="https://github.com/wzpan/hexo-generator-search" target="_blank" rel="noopener" style="color:#49B1F5;">hexo-generator-search</a>
 <span>提供支持</span></div></div></div><span class="search-close-button"><i class="fa fa-times"></i></span></div><div class="search-mask"></div></body></html>